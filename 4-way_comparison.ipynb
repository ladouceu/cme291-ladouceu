{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b08128",
   "metadata": {},
   "source": [
    "# 4-way Comparison\n",
    "The purpose of this notebook is to compare the binomial tree (BT), Longstaff-Shwartz (LS), Approximate Dynamic Programming (ADP), and Reinforcement Learning (RL). We consider both the pricing of vanilla american put and call options. We also compare our solution to that of Black-Scholes (BS) for European put and call option pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de28376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should permanantly add this path to pythonpath instead\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\frede\\MCF_Workspace\\cme291-aut21\\RL-book') # clone the RL-book repo and put its path here\n",
    "import matplotlib.pyplot as plt\n",
    "####\n",
    "\n",
    "from dataclasses import dataclass, replace\n",
    "from typing import Callable, Tuple, Iterator, Sequence, List\n",
    "import numpy as np\n",
    "from rl.dynamic_programming import V\n",
    "from scipy.stats import norm\n",
    "from rl.markov_decision_process import MarkovDecisionProcess, State, Terminal, NonTerminal\n",
    "from rl.policy import FiniteDeterministicPolicy, DeterministicPolicy\n",
    "from rl.distribution import Constant, Categorical, SampledDistribution\n",
    "from rl.finite_horizon import optimal_vf_and_policy\n",
    "from modified_rl_book_code.function_approx_fred import FunctionApprox, LinearFunctionApprox, LinearInterpolationApprox,\\\n",
    "                                 BSplineApprox, AdamGradient  # TODO: \"Change to not fred?\n",
    "from modified_rl_book_code.approximate_dynamic_programming_fred import back_opt_vf_and_policy # TODO: Change to not fred?\n",
    "from rl.gen_utils.plot_funcs import plot_list_of_curves\n",
    "from numpy.polynomial.laguerre import lagval\n",
    "from scipy.stats import norm\n",
    "\n",
    "TrainingDataType = Tuple[int, float, float]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db3586",
   "metadata": {},
   "source": [
    "## Helper Classes and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763014e",
   "metadata": {},
   "source": [
    "### European Option Pricing using Black-Scholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f61aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def european_price(is_call: bool, strike: float, vol: float, expiry: float,\n",
    "                   spot_price: float, rate: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the price of an european option (put or call) computed using BS solution.\n",
    "    \"\"\"\n",
    "    sigma_sqrt: float = vol * np.sqrt(expiry)\n",
    "    d1: float = (np.log(spot_price / strike) +\n",
    "                 (rate + vol ** 2 / 2.) * expiry) \\\n",
    "        / sigma_sqrt\n",
    "    d2: float = d1 - sigma_sqrt\n",
    "    if is_call:\n",
    "        ret = spot_price * norm.cdf(d1) - \\\n",
    "            strike * np.exp(-rate * expiry) * norm.cdf(d2)\n",
    "    else:\n",
    "        ret = strike * np.exp(-rate * expiry) * norm.cdf(-d2) - \\\n",
    "            spot_price * norm.cdf(-d1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8cb57",
   "metadata": {},
   "source": [
    "### American Option Pricing using Binomial Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb0c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class OptimalExerciseBinTree:\n",
    "\n",
    "    spot_price: float\n",
    "    payoff: Callable[[float, float], float]\n",
    "    expiry: float\n",
    "    rate: float\n",
    "    vol: float\n",
    "    num_steps: int \n",
    "\n",
    "    def dt(self) -> float:\n",
    "        \"\"\"\n",
    "        Get the time interval size used for discretization \n",
    "        \"\"\"\n",
    "        return self.expiry / self.num_steps\n",
    "\n",
    "    def state_price(self, i: int, j: int) -> float:\n",
    "        \"\"\"\n",
    "        Get the price associated with state j of time step i.\n",
    "        \"\"\"\n",
    "        return self.spot_price * np.exp((2 * j - i) * self.vol *\n",
    "                                        np.sqrt(self.dt()))\n",
    "\n",
    "    def get_opt_vf_and_policy(self) -> \\\n",
    "            Iterator[Tuple[V[int], FiniteDeterministicPolicy[int, bool]]]:\n",
    "        \"\"\"\n",
    "        Compute the optimal value functions and optimal policies for each time step by backward induction.\n",
    "        \"\"\"\n",
    "        dt: float = self.dt()\n",
    "        up_factor: float = np.exp(self.vol * np.sqrt(dt))\n",
    "        up_prob: float = (np.exp(self.rate * dt) * up_factor - 1) / \\\n",
    "            (up_factor * up_factor - 1)\n",
    "        # this step calls this function from the finite_horizon module.\n",
    "        return optimal_vf_and_policy( \n",
    "            steps=[\n",
    "                {NonTerminal(j): {\n",
    "                    True: Constant(\n",
    "                        (\n",
    "                            Terminal(-1),\n",
    "                            self.payoff(self.state_price(i, j))\n",
    "                        )\n",
    "                    ),\n",
    "                    False: Categorical(\n",
    "                        {\n",
    "                            (NonTerminal(j + 1), 0.): up_prob,\n",
    "                            (NonTerminal(j),     0.): 1 - up_prob\n",
    "                        }\n",
    "                    )\n",
    "                } for j in range(i + 1)}\n",
    "                for i in range(self.num_steps + 1)\n",
    "            ],\n",
    "            gamma=np.exp(-self.rate * dt)\n",
    "        )\n",
    "\n",
    "    def option_exercise_boundary(\n",
    "        self,\n",
    "        policy_seq: Sequence[FiniteDeterministicPolicy[int, bool]],\n",
    "        is_call: bool\n",
    "    ) -> Sequence[Tuple[float, float]]:\n",
    "        dt: float = self.dt()\n",
    "        ex_boundary: List[Tuple[float, float]] = []\n",
    "        for i in range(self.num_steps + 1):\n",
    "            ex_points = [j for j in range(i + 1)\n",
    "                         if policy_seq[i].action_for[j] and\n",
    "                         self.payoff(self.state_price(i, j)) > 0]\n",
    "            if len(ex_points) > 0:\n",
    "                boundary_pt = min(ex_points) if is_call else max(ex_points)\n",
    "                ex_boundary.append(\n",
    "                    (i * dt, self.state_price(i, boundary_pt))\n",
    "                )\n",
    "        return ex_boundary\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306218bb",
   "metadata": {},
   "source": [
    "### American Option Pricing using Approximate Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b02b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (almost) original code using linear function approximation\n",
    "@dataclass(frozen=True)\n",
    "class OptimalExerciseADP:\n",
    "    '''Optimal Exercise with Backward Induction when the underlying\n",
    "    price follows a lognormal process'''\n",
    "\n",
    "    spot_price: float\n",
    "    payoff: Callable[[float], float]\n",
    "    expiry: float\n",
    "    rate: float\n",
    "    vol: float\n",
    "    num_steps: int\n",
    "    spot_price_frac: float\n",
    "    num_state_samples: int\n",
    "    num_expectation_samples: int\n",
    "\n",
    "    def get_mdp(self, t: int) -> MarkovDecisionProcess[float, bool]:\n",
    "        dt: float = self.expiry / self.num_steps\n",
    "        exer_payoff: Callable[[float], float] = self.payoff\n",
    "        r: float = self.rate\n",
    "        s: float = self.vol\n",
    "\n",
    "        class OptExerciseADPMDP(MarkovDecisionProcess[float, bool]):\n",
    "            \n",
    "            def __init__(self, num_state_samples, num_expectation_samples):\n",
    "                self.num_state_samples = num_state_samples\n",
    "                self.num_expectation_samples = num_expectation_samples\n",
    "        \n",
    "            def step(\n",
    "                self,\n",
    "                price: NonTerminal[float],\n",
    "                exer: bool\n",
    "            ) -> SampledDistribution[Tuple[State[float], float]]:\n",
    "\n",
    "                def sr_sampler_func(\n",
    "                    price=price,\n",
    "                    exer=exer\n",
    "                ) -> Tuple[State[float], float]:\n",
    "                    if exer:\n",
    "                        return Terminal(0.), exer_payoff(price.state)\n",
    "                    else:\n",
    "                        next_price: float = np.exp(np.random.normal(\n",
    "                            np.log(price.state) + (r - s * s / 2) * dt,\n",
    "                            s * np.sqrt(dt)\n",
    "                        ))\n",
    "                        return NonTerminal(next_price), 0.\n",
    "\n",
    "#                 num_expectation_samples = 200\n",
    "                return SampledDistribution(\n",
    "                    sampler=sr_sampler_func,\n",
    "                    expectation_samples=self.num_expectation_samples # 200\n",
    "                )\n",
    "\n",
    "            def actions(self, price: NonTerminal[float]) -> Sequence[bool]:\n",
    "                return [True, False]\n",
    "\n",
    "        return OptExerciseADPMDP(self.num_state_samples, self.num_expectation_samples)\n",
    "\n",
    "    \n",
    "    # this method is only used once in the method backward_induction_vf_and_pi. It is used \n",
    "    # to sample the states to sample to make the updates to the ADP function approx.\n",
    "    # I would like to have it sample a few more outliers because the function approximation\n",
    "    # tends to overfit the sample that are in a high density region. \n",
    "    def get_states_distribution( \n",
    "        self,\n",
    "        t: int\n",
    "    ) -> SampledDistribution[NonTerminal[float]]:\n",
    "        spot_mean2: float = self.spot_price * self.spot_price\n",
    "        spot_var: float = spot_mean2 * \\\n",
    "            self.spot_price_frac * self.spot_price_frac\n",
    "        log_mean: float = np.log(spot_mean2 / np.sqrt(spot_var + spot_mean2))\n",
    "        log_stdev: float = np.sqrt(np.log(spot_var / spot_mean2 + 1))\n",
    "\n",
    "        time: float = t * self.expiry / self.num_steps\n",
    "\n",
    "        def states_sampler_func() -> NonTerminal[float]:\n",
    "            start: float = np.random.lognormal(log_mean, log_stdev) \n",
    "            price = np.exp(np.random.normal(\n",
    "                np.log(start) + (self.rate - self.vol * self.vol / 2) * time,\n",
    "                self.vol * np.sqrt(time)\n",
    "#                 self.vol * np.sqrt(time)*1.1  # I modified this line to have more variance (added the *1.1)\n",
    "            ))\n",
    "            return NonTerminal(price)\n",
    "\n",
    "        return SampledDistribution(states_sampler_func)\n",
    "\n",
    "    def get_vf_func_approx(\n",
    "        self,\n",
    "        t: int,\n",
    "        features: Sequence[Callable[[NonTerminal[float]], float]],\n",
    "        reg_coeff: float\n",
    "    ) -> LinearFunctionApprox[NonTerminal[float]]:\n",
    "        return LinearFunctionApprox.create(\n",
    "            feature_functions=features,\n",
    "            regularization_coeff=reg_coeff,\n",
    "            direct_solve=True\n",
    "        )\n",
    "\n",
    "    def backward_induction_vf_and_pi(\n",
    "        self,\n",
    "        features: Sequence[Callable[[NonTerminal[float]], float]],\n",
    "        reg_coeff: float\n",
    "    ) -> Iterator[\n",
    "        Tuple[FunctionApprox[NonTerminal[float]],\n",
    "              DeterministicPolicy[float, bool]]\n",
    "    ]:\n",
    "\n",
    "        mdp_f0_mu_triples: Sequence[Tuple[\n",
    "            MarkovDecisionProcess[float, bool],\n",
    "            FunctionApprox[NonTerminal[float]],\n",
    "            SampledDistribution[NonTerminal[float]]\n",
    "        ]] = [(\n",
    "            self.get_mdp(t=i),\n",
    "            self.get_vf_func_approx(\n",
    "                t=i,\n",
    "                features=features,\n",
    "                reg_coeff=reg_coeff\n",
    "            ),\n",
    "            self.get_states_distribution(t=i)\n",
    "        ) for i in range(self.num_steps + 1)]\n",
    "\n",
    "#         num_state_samples: int = 1000 #1000\n",
    "\n",
    "        return back_opt_vf_and_policy(\n",
    "            mdp_f0_mu_triples=mdp_f0_mu_triples,\n",
    "            Î³=np.exp(-self.rate * self.expiry / self.num_steps),\n",
    "            num_state_samples=self.num_state_samples,\n",
    "            error_tolerance=1e-8, #TODO: remove\n",
    "            mode = \"put\"\n",
    "        )\n",
    "\n",
    "    def optimal_value_curve(\n",
    "        self,\n",
    "        func: FunctionApprox[NonTerminal[float]],\n",
    "        prices: Sequence[float]\n",
    "    ) -> np.ndarray:\n",
    "        return func.evaluate([NonTerminal(p) for p in prices])\n",
    "\n",
    "    def exercise_curve(\n",
    "        self,\n",
    "        prices: Sequence[float]\n",
    "    ) -> np.ndarray:\n",
    "        return np.array([self.payoff(p) for p in prices])\n",
    "\n",
    "    def put_option_exercise_boundary(\n",
    "        self,\n",
    "        opt_vfs: Sequence[FunctionApprox[NonTerminal[float]]],\n",
    "        strike: float\n",
    "    ) -> Sequence[float]:\n",
    "        ret: List[float] = []\n",
    "        prices: np.ndarray = np.arange(0., strike + 0.1, 0.1)\n",
    "        for vf in opt_vfs[:-1]:\n",
    "            cp: np.ndarray = self.optimal_value_curve(\n",
    "                func=vf,\n",
    "                prices=prices\n",
    "            )\n",
    "            ep: np.ndarray = self.exercise_curve(prices=prices)\n",
    "            ll: Sequence[float] = [p for p, c, e in zip(prices, cp, ep)\n",
    "                                   if e > c]\n",
    "            ret.append(max(ll) if len(ll) > 0 else 0.)\n",
    "        final: Sequence[Tuple[float, float]] = \\\n",
    "            [(p, self.payoff(p)) for p in prices]\n",
    "        ret.append(max(p for p, e in final if e > 0))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616bd28",
   "metadata": {},
   "source": [
    "### American Option Pricing using Longstaff-Shwartz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34ca325",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class OptimalExerciseLS:\n",
    "    \n",
    "    spot_price: float\n",
    "    payoff: Callable[[float], float]\n",
    "    expiry: float\n",
    "    rate: float\n",
    "    vol: float\n",
    "    num_steps: int\n",
    "    spot_price_frac: float # better name than spot_price_frac\n",
    "       \n",
    "    # TODO why do we have a spot_price_frac?\n",
    "    # TODO verify that my process behaves correctly\n",
    "    # TODO check that I get the same results as Prof Rao's original code\n",
    "#     @memoize\n",
    "    def _get_all_paths(\n",
    "        self,\n",
    "        spot_price_frac: float,\n",
    "        num_paths: int,\n",
    "        num_dt: int\n",
    "    ) -> np.ndarray:\n",
    "        dt = self.expiry / num_dt\n",
    "        paths = np.empty([num_paths, num_dt + 1])\n",
    "        spot = self.spot_price\n",
    "        for i in range(num_paths):\n",
    "            start = max(0.001, np.random.normal(spot, spot * spot_price_frac))\n",
    "            paths[i, 0] = start\n",
    "            for t in range(num_dt):\n",
    "                mean = np.log(paths[i,t]) + (self.rate - self.vol * self.vol / 2) * dt\n",
    "                std  = self.vol * np.sqrt(dt) \n",
    "                paths[i, t + 1] = np.exp(np.random.normal(mean, std))\n",
    "        return paths\n",
    "\n",
    "\n",
    "    # TODO: verify that the discount I use is OK\n",
    "    # TODO: may operations could be vectorized\n",
    "    def get_price(\n",
    "        self,\n",
    "        num_dt: int,\n",
    "        num_paths: int,\n",
    "        feature_funcs: Sequence[Callable[[NonTerminal[float]], float]]\n",
    "    ) -> float:\n",
    "        paths = self._get_all_paths(0.0, num_paths, num_dt)\n",
    "\n",
    "        cashflow = np.array([self.payoff(paths[i,-1])\n",
    "                             for i in range(num_paths)])\n",
    "        dt = self.expiry / num_dt\n",
    "\n",
    "        ex_boundary_price_range = (0,80)  # TODO: this approach won't work for call options (no need for boundary in call \n",
    "                                           #       options) Also, this is hardcoded stike price. I did change the stprcs uses\n",
    "                                            # below with path_values\n",
    "        stprcs = np.arange(*ex_boundary_price_range)\n",
    "        final = [(p, self.payoff(p)) for p in stprcs]\n",
    "        ex_boundary = [max(p for p, e in final if e > 0)]\n",
    "        vf_seq = [final]\n",
    "        for step in range(num_dt - 1, 0, -1):\n",
    "            \"\"\"\n",
    "            For each time slice t\n",
    "            Step 1: collect X as features of (t, [S_0,.., S_t]) for those paths\n",
    "            for which payoff(t, [S_0, ...., S_t]) > 0, and corresponding Y as\n",
    "            the time-t discounted future actual cash flow on those paths.\n",
    "            Step 2: Do the (X,Y) regression. Denote Y^ as regression-prediction.\n",
    "            Compare Y^ versus payoff(t, [S_0, ..., S_t]). If payoff is higher,\n",
    "            set cashflow at time t on that path to be the payoff, else set \n",
    "            cashflow at time t on that path to be the time-t discounted future\n",
    "            actual cash flow on that path.\n",
    "            \"\"\"\n",
    "            t = step * dt\n",
    "            disc = np.exp(-self.rate * dt)\n",
    "            cashflow = cashflow * disc\n",
    "            payoff = np.array([self.payoff(paths[i,step]) for i in range(num_paths)])\n",
    "            indices = [i for i in range(num_paths) if payoff[i] > 0]\n",
    "            if len(indices) > 0:\n",
    "                path_values = sorted([paths[i, step] for i in indices])\n",
    "                x_vals = np.array([[f(NonTerminal(paths[i, step])) for f in feature_funcs] for i in indices])\n",
    "                y_vals = np.array([cashflow[i] for i in indices])\n",
    "                weights = np.linalg.lstsq(x_vals, y_vals, rcond=None)[0]\n",
    "                estimate = x_vals.dot(weights)\n",
    "#                 plt.scatter([paths[i, step] for i in indices], y_vals, c='r')\n",
    "#                 plt.scatter([paths[i, step] for i in indices], estimate, c='b')\n",
    "#                 plt.plot([paths[i, step] for i in indices], [self.payoff(paths[i, step]) for i in indices], c='g')\n",
    "#                 plt.show()\n",
    "\n",
    "                for i, ind in enumerate(indices):\n",
    "                    if payoff[ind] > estimate[i]:\n",
    "                        cashflow[ind] = payoff[ind]\n",
    "\n",
    "                cp = [weights.dot([f(NonTerminal(s)) for f in feature_funcs]) for s in path_values]\n",
    "                ep = [self.payoff(s) for s in path_values]\n",
    "                op = [(path_values[j],max(cp[j],ep[j])) for j in range(len(path_values))]\n",
    "                vf_seq.append(op)\n",
    "                ll = [p for p, c, e in zip(path_values, cp, ep) if e > c]\n",
    "                if len(ll) == 0:\n",
    "                    num = 0. # TODO: check if the following lines that I added (instead of simply setting to 0, set to previous value)\n",
    "#                     if len(ex_boundary) != 0:\n",
    "#                         num = ex_boundary[-1]\n",
    "#                     else:\n",
    "#                         num = 0\n",
    "                else:\n",
    "                    num = max(ll)\n",
    "                ex_boundary.append(num)\n",
    "#                 # plot the continuation and exercise value functions at step step\n",
    "#                 if step % 10 == 0:\n",
    "#                     plt.title(\"LS Time = %.3f\" % t)\n",
    "#                     plt.scatter([paths[i, step] for i in indices], y_vals,s=5)\n",
    "#                     plt.plot(path_values, cp, 'r', path_values, ep, 'b')\n",
    "#                     plt.show()\n",
    "\n",
    "        vf_seq.append([(self.spot_price,max(self.payoff(self.spot_price),np.average(cashflow * np.exp(-self.rate * dt))))])\n",
    "\n",
    "        return max(\n",
    "            self.payoff(self.spot_price),\n",
    "            np.average(cashflow * np.exp(-self.rate * dt))\n",
    "        ), ex_boundary[::-1], vf_seq[::-1] #TODO: I think I have reversed it\n",
    "                       #TODO: only have the exercise boundary if it is a put option\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e33af",
   "metadata": {},
   "source": [
    "### American Option Pricing using Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f9ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class OptimalExerciseRL:\n",
    "\n",
    "    spot_price: float\n",
    "    payoff: Callable[[float], float]\n",
    "    expiry: float\n",
    "    rate: float\n",
    "    vol: float\n",
    "    num_steps: int \n",
    "        \n",
    "    def training_sim_data(\n",
    "        self,\n",
    "        num_paths: int,\n",
    "        spot_price_frac: float\n",
    "    ) -> Sequence[TrainingDataType]:\n",
    "        ret: List[TrainingDataType] = []\n",
    "        dt: float = self.expiry / self.num_steps\n",
    "        spot: float = self.spot_price\n",
    "        vol2: float = self.vol * self.vol\n",
    "\n",
    "        mean2: float = spot * spot\n",
    "        var: float = mean2 * spot_price_frac * spot_price_frac\n",
    "        log_mean: float = np.log(mean2 / np.sqrt(var + mean2))\n",
    "        log_stdev: float = np.sqrt(np.log(var / mean2 + 1))\n",
    "\n",
    "        for i in range(num_paths):\n",
    "            price: float = np.random.lognormal(log_mean, log_stdev)\n",
    "            for step in range(self.num_steps):\n",
    "                m: float = np.log(price) + (self.rate - vol2 / 2) * dt\n",
    "                v: float = vol2 * dt\n",
    "                next_price: float = np.exp(np.random.normal(m, np.sqrt(v)))\n",
    "                ret.append((step, price, next_price))\n",
    "                price = next_price\n",
    "        return ret\n",
    "    \n",
    "    def scoring_sim_data(self, num_paths: int) -> np.ndarray:\n",
    "        paths: np.ndarray = np.empty([num_paths, self.num_steps + 1])\n",
    "        dt: float = self.expiry / self.num_steps\n",
    "        vol2: float = self.vol * self.vol\n",
    "        for i in range(num_paths):\n",
    "            paths[i, 0] = self.spot_price\n",
    "            for step in range(self.num_steps):\n",
    "                m: float = np.log(paths[i, step]) + (self.rate - vol2 / 2) * dt\n",
    "                v: float = vol2 * dt\n",
    "                paths[i, step + 1] = np.exp(np.random.normal(m, np.sqrt(v)))\n",
    "        return paths\n",
    "    \n",
    "    def linear_func_approx(\n",
    "        self,\n",
    "        features: Sequence[Callable[[Tuple[float, float]], float]],\n",
    "        reg: float\n",
    "    ) -> LinearFunctionApprox[Tuple[float, float]]:\n",
    "        return LinearFunctionApprox.create(\n",
    "            feature_functions=features,\n",
    "            adam_gradient=self.adam_gradient(),\n",
    "            regularization_coeff=reg\n",
    "        )\n",
    "    \n",
    "    def adam_gradient(self) -> AdamGradient:\n",
    "        return AdamGradient(\n",
    "            learning_rate=0.1,\n",
    "            decay1=0.9,\n",
    "            decay2=0.999\n",
    "        )\n",
    "    \n",
    "    def train_lspi(\n",
    "        self,\n",
    "        training_data: Sequence[TrainingDataType],\n",
    "        init_fa: LinearFunctionApprox[Tuple[float, float]],\n",
    "        training_iters: int,\n",
    "        split: int\n",
    "    ) -> LinearFunctionApprox[Tuple[float, float]]:\n",
    "        fa: LinearFunctionApprox[Tuple[float, float]] = init_fa\n",
    "        dt: float = self.expiry / self.num_steps\n",
    "        gamma: float = np.exp(-self.rate * dt)\n",
    "        num_features: int = len(fa.feature_functions)\n",
    "        states: Sequence[Tuple[float, float]] = [(i * dt, s) for\n",
    "                                                 i, s, _ in training_data]\n",
    "        next_states: Sequence[Tuple[float, float]] = \\\n",
    "            [((i + 1) * dt, s1) for i, _, s1 in training_data]\n",
    "        features: np.ndarray = fa.get_feature_values(states)\n",
    "        next_features: np.ndarray = fa.get_feature_values(next_states)\n",
    "        non_terminal: np.ndarray = np.array(\n",
    "            [i < self.num_steps - 1 for i, _, _ in training_data]\n",
    "        )\n",
    "        exer: np.ndarray = np.array([self.payoff(s1)\n",
    "                                     for t1, s1 in next_states])\n",
    "        reg_mat: np.ndarray = fa.regularization_coeff * \\\n",
    "            np.eye(len(fa.feature_functions))\n",
    "        for i in range(training_iters):\n",
    "            a_mat: np.ndarray = np.zeros([num_features, num_features])\n",
    "            b_vec: np.ndarray = np.zeros(num_features)\n",
    "            cont: np.ndarray = fa.evaluate(next_states)\n",
    "            cont_cond: np.ndarray = non_terminal * (cont > exer)\n",
    "            features_split: Sequence[np.ndarray] = \\\n",
    "                np.array_split(features, split)\n",
    "            next_features_split: Sequence[np.ndarray] = \\\n",
    "                np.array_split(next_features, split, axis=0)\n",
    "            cont_cond_split: Sequence[np.ndarray] = \\\n",
    "                np.array_split(cont_cond, split)\n",
    "            exer_split: Sequence[np.ndarray] = np.array_split(exer, split)\n",
    "            for i in range(split):\n",
    "                a_mat += features_split[i].T.dot(\n",
    "                    features_split[i] - np.diag(cont_cond_split[i]).dot(\n",
    "                        next_features_split[i] * gamma\n",
    "                    )\n",
    "                )\n",
    "                b_vec += features_split[i].T.dot(\n",
    "                    (1 - cont_cond_split[i]) * exer_split[i] * gamma\n",
    "                )\n",
    "            a_mat /= len(training_data)\n",
    "            a_mat += reg_mat\n",
    "            b_vec /= len(training_data)\n",
    "            wts: np.ndarray = np.linalg.solve(a_mat, b_vec)\n",
    "            fa = replace(\n",
    "                fa,\n",
    "                weights=replace(\n",
    "                    fa.weights,\n",
    "                    weights=wts\n",
    "                )\n",
    "            )\n",
    "        return fa\n",
    "    \n",
    "    def continuation_curve(\n",
    "        self,\n",
    "        func: FunctionApprox[Tuple[float, float]],\n",
    "        step: int,\n",
    "        prices: Sequence[float]\n",
    "    ) -> np.ndarray:\n",
    "        t: float = step * self.expiry / self.num_steps\n",
    "        return func.evaluate([(t, p) for p in prices])\n",
    "    \n",
    "    def exercise_curve(\n",
    "        self,\n",
    "        step: int,\n",
    "        prices: Sequence[float]\n",
    "    ) -> np.ndarray:\n",
    "        t: float = step * self.expiry / self.num_steps\n",
    "        return np.array([self.payoff(p) for p in prices])\n",
    "\n",
    "    def put_option_exercise_boundary(\n",
    "        self,\n",
    "        func: FunctionApprox[Tuple[float, float]],\n",
    "        strike: float\n",
    "    ) -> Sequence[float]:\n",
    "        ret: List[float] = []\n",
    "        prices: np.ndarray = np.arange(0., strike + 0.1, 0.1)\n",
    "        for step in range(self.num_steps):\n",
    "            cp: np.ndarray = self.continuation_curve(\n",
    "                func=func,\n",
    "                step=step,\n",
    "                prices=prices\n",
    "            )\n",
    "            ep: np.ndarray = self.exercise_curve(step=step, prices=prices)\n",
    "            ll: Sequence[float] = [p for p, c, e in zip(prices, cp, ep)\n",
    "                                   if e > c]\n",
    "            ret.append(max(ll) if len(ll) > 0 else 0.)\n",
    "        final: Sequence[Tuple[float, float]] = \\\n",
    "            [(p, self.payoff(p)) for p in prices]\n",
    "        ret.append(max(p for p, e in final if e > 0))\n",
    "        return ret\n",
    "    \n",
    "    def option_price(\n",
    "        self,\n",
    "        scoring_data: np.ndarray,\n",
    "        func: FunctionApprox[Tuple[float, float]]\n",
    "    ) -> float:\n",
    "        num_paths: int = scoring_data.shape[0]\n",
    "        prices: np.ndarray = np.zeros(num_paths)\n",
    "        dt: float = self.expiry / self.num_steps\n",
    "\n",
    "        for i, path in enumerate(scoring_data):\n",
    "            step: int = 0\n",
    "            while step <= self.num_steps:\n",
    "                t: float = step * dt\n",
    "                exercise_price: float = self.payoff(path[step])\n",
    "                continue_price: float = func.evaluate([(t, path[step])])[0] \\\n",
    "                    if step < self.num_steps else 0.\n",
    "                step += 1\n",
    "                if exercise_price >= continue_price:\n",
    "                    prices[i] = np.exp(-self.rate * t) * exercise_price\n",
    "                    step = self.num_steps + 1\n",
    "\n",
    "        return np.average(prices)\n",
    "    \n",
    "    \n",
    "def fitted_lspi_put_option(\n",
    "    obj: OptimalExerciseRL,\n",
    "    strike: float,\n",
    "    expiry: float,\n",
    "    training_data: Sequence[TrainingDataType],\n",
    "    training_iters: int,\n",
    "    split: int\n",
    ") -> LinearFunctionApprox[Tuple[float, float]]:\n",
    "\n",
    "    num_laguerre: int = 3\n",
    "    lspi_reg: float = 0.001\n",
    "\n",
    "    ident: np.ndarray = np.eye(num_laguerre)\n",
    "    features: List[Callable[[Tuple[float, float]], float]] = [lambda _: 1.]\n",
    "    features += [(lambda t_s: np.exp(-t_s[1] / (2 * strike)) *\n",
    "                  lagval(t_s[1] / strike, ident[i]))\n",
    "                 for i in range(num_laguerre)]\n",
    "    features += [\n",
    "        lambda t_s: np.cos(-t_s[0] * np.pi / (2 * expiry)),\n",
    "        lambda t_s: np.log(expiry - t_s[0]) if t_s[0] != expiry else 0.,\n",
    "        lambda t_s: (t_s[0] / expiry) ** 2\n",
    "    ]\n",
    "\n",
    "    linear_approx: LinearFunctionApprox[Tuple[float, float]] = \\\n",
    "        obj.linear_func_approx(features=features, reg=lspi_reg)\n",
    "\n",
    "    return obj.train_lspi(\n",
    "        training_data=training_data,\n",
    "        init_fa=linear_approx,\n",
    "        training_iters=training_iters,\n",
    "        split=split\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c1e78",
   "metadata": {},
   "source": [
    "## Perform the pricing (with Linear Function Approximation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bce8a",
   "metadata": {},
   "source": [
    "### problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac1feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "spot_price_val: float = 100.0 #100.0\n",
    "strike_val: float = 100.0 #100.0\n",
    "is_call_val: bool = False  #False\n",
    "expiry_val: float = 1.0 #1.0\n",
    "rate_val: float = 0.05 #0.05\n",
    "vol_val: float = 0.25 #0.25\n",
    "spot_price_frac_val: float = 0.02\n",
    "seed_val = 0\n",
    "skip_size_val = 0.2 # for VF visualization\n",
    "# algo. specific parameters\n",
    "num_steps_val_best: int = 1000 #300\n",
    "num_steps_val_bin_tree: int = 200 #300\n",
    "num_steps_val_adp: int = 5 #10\n",
    "num_state_samples_val_adp: int = 1000 #1000\n",
    "num_expectation_samples_val_adp: int = 200 #200\n",
    "num_steps_val_ls: int = 100 #300\n",
    "num_paths_val_ls = 1000 #10000\n",
    "num_steps_val_rl: int = 5 #300\n",
    "num_training_paths_val_rl: int = 5000 #5000\n",
    "num_scoring_paths_val_rl: int = 10000 #10000\n",
    "num_training_iters_val_rl: int = 8 #8\n",
    "split_val_rl: int = 1000#1000\n",
    "    \n",
    "# get the steps sizes\n",
    "dt_best = expiry_val / num_steps_val_best\n",
    "dt_bin_tree = expiry_val / num_steps_val_bin_tree\n",
    "dt_adp = expiry_val / num_steps_val_adp\n",
    "dt_ls = expiry_val / num_steps_val_ls\n",
    "dt_rl: float = expiry_val / num_steps_val_rl\n",
    "    \n",
    "# assert that the step size is a dividor of 10% TODO: improve this assertion\n",
    "assert(1000*skip_size_val*expiry_val % (1000 * dt_best) == 0.0)\n",
    "assert(1000*skip_size_val*expiry_val % (1000 * dt_bin_tree) == 0.0)\n",
    "assert(1000*skip_size_val*expiry_val % (1000 * dt_adp) == 0.0)\n",
    "assert(1000*skip_size_val*expiry_val % (1000 * dt_ls) == 0.0)\n",
    "assert(1000*skip_size_val*expiry_val % (1000 * dt_rl) == 0.0)\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(seed_val)\n",
    "    \n",
    "# define different payoffs if call or put option\n",
    "if is_call_val:\n",
    "    opt_payoff: Callable[[float],float] = lambda x: max(x - strike_val, 0)\n",
    "else:\n",
    "    opt_payoff: Callable[[float],float] = lambda x: max(strike_val - x, 0)\n",
    "\n",
    "# define the features to use for the linear function approximation\n",
    "num_laguerre_val: int = 4 # 4\n",
    "reglr_coeff_val: float = 0.01 #0.001 (I should play with that)\n",
    "\n",
    "# define my feature functions (laguerre polynomials)\n",
    "def laguerre_feature_func(\n",
    "    s: NonTerminal[float],\n",
    "    i: int,\n",
    "    n: int,\n",
    "    strike: float\n",
    ") -> float:\n",
    "    xp = s.state / strike\n",
    "    coef = np.zeros((n,))\n",
    "    coef[i] = 1\n",
    "    return np.exp(-xp / 2) * lagval(xp, coef)\n",
    "\n",
    "ffs: List[Callable[[NonTerminal[float]], float]] = [lambda _: 1.]\n",
    "for i in range(num_laguerre_val):\n",
    "    ff = lambda s,i=i: laguerre_feature_func(s,i,num_laguerre_val,strike_val)\n",
    "    ffs += [ff]\n",
    "    \n",
    "\n",
    "def ex_boundary_error_metric(x_truth, y_truth, x_boundary, y_boundary):\n",
    "    def get_prob(t,p):\n",
    "        return norm.pdf(np.log(p/spot_price_val),(rate_val - vol_val * vol_val / 2) * t, vol_val * np.sqrt(t))\n",
    "    \n",
    "    x_truth = np.array(x_truth)\n",
    "    y_truth = np.array(y_truth)\n",
    "    x_boundary = np.array(x_boundary)\n",
    "    y_boundary = np.array(y_boundary)\n",
    "    \n",
    "    summ = 0\n",
    "    normalizer = 0\n",
    "    for i in range(len(x_boundary)):\n",
    "        # find the index of the x_truth closest to x_boundary[i]\n",
    "        idx = np.argmin(np.abs(x_truth - x_boundary[i]))\n",
    "        # get the x_truth,y_truth for this index\n",
    "        x,y = x_truth[idx],y_truth[idx]\n",
    "        # get the probability of reaching this point x,y\n",
    "        w = get_prob(x,y)\n",
    "        # get the absolute difference of this y and y_boundary[i]\n",
    "        abs_diff = np.abs(y_boundary[i] - y)\n",
    "        # perform weighted sum\n",
    "        summ += w * abs_diff\n",
    "        normalizer += w\n",
    "    summ /= normalizer\n",
    "    return summ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d03ce",
   "metadata": {},
   "source": [
    "### price european option with Black-Scholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2863b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bs: float = european_price(is_call_val, strike_val, vol_val, expiry_val, spot_price_val, rate_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105f063",
   "metadata": {},
   "source": [
    "### price american option with BEST model (Binary Tree with many steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2458ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ex_best: OptimalExerciseBinTree = OptimalExerciseBinTree(\n",
    "    spot_price=spot_price_val,\n",
    "    payoff=opt_payoff,\n",
    "    expiry=expiry_val,\n",
    "    rate=rate_val,\n",
    "    vol=vol_val,\n",
    "    num_steps=num_steps_val_best\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "# get the optimal value functions and policy for each time step using backward induction\n",
    "vf_seq_best, policy_seq_best = zip(*opt_ex_best.get_opt_vf_and_policy())\n",
    "\n",
    "# get the exercise boundary\n",
    "ex_boundary_best: Sequence[Tuple[float, float]] = \\\n",
    "    opt_ex_best.option_exercise_boundary(policy_seq_best, is_call_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86b8cf",
   "metadata": {},
   "source": [
    "### price american option with Binary Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c531379",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ex_bin_tree: OptimalExerciseBinTree = OptimalExerciseBinTree(\n",
    "    spot_price=spot_price_val,\n",
    "    payoff=opt_payoff,\n",
    "    expiry=expiry_val,\n",
    "    rate=rate_val,\n",
    "    vol=vol_val,\n",
    "    num_steps=num_steps_val_bin_tree\n",
    ")\n",
    "    \n",
    "# get the optimal value functions and policy for each time step using backward induction\n",
    "vf_seq_bin_tree, policy_seq_bin_tree = zip(*opt_ex_bin_tree.get_opt_vf_and_policy())\n",
    "\n",
    "# get the exercise boundary\n",
    "ex_boundary_bin_tree: Sequence[Tuple[float, float]] = \\\n",
    "    opt_ex_bin_tree.option_exercise_boundary(policy_seq_bin_tree, is_call_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8b448",
   "metadata": {},
   "source": [
    "### price american option with ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8567b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ex_adp: OptimalExerciseADP = OptimalExerciseADP(\n",
    "    spot_price=spot_price_val,\n",
    "    payoff=opt_payoff,\n",
    "    expiry=expiry_val,\n",
    "    rate=rate_val,\n",
    "    vol=vol_val,\n",
    "    num_steps=num_steps_val_adp,\n",
    "    spot_price_frac=spot_price_frac_val,\n",
    "    num_state_samples = num_state_samples_val_adp,\n",
    "    num_expectation_samples = num_expectation_samples_val_adp\n",
    ")\n",
    "\n",
    "it_vf_adp = opt_ex_adp.backward_induction_vf_and_pi(\n",
    "    features=ffs,\n",
    "    reg_coeff=reglr_coeff_val\n",
    ")\n",
    "it_vf_adp = list(it_vf_adp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79650416",
   "metadata": {},
   "source": [
    "### price american option with LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b9c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the OptimalExerciseLS class which computes price and exercise boundary\n",
    "opt_ex_ls: OptimalExerciseLS = OptimalExerciseLS(\n",
    "                                    spot_price = spot_price_val,\n",
    "                                    payoff = opt_payoff,\n",
    "                                    expiry = expiry_val,\n",
    "                                    rate = rate_val,\n",
    "                                    vol = vol_val,\n",
    "                                    num_steps = num_steps_val_ls,\n",
    "                                    spot_price_frac = spot_price_frac_val)\n",
    "        \n",
    "# get price\n",
    "price_ls, ex_boundary_ls, vf_seq_ls = opt_ex_ls.get_price(num_steps_val_ls, num_paths_val_ls, ffs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ad4f8",
   "metadata": {},
   "source": [
    "### price american option with RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a243562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the class\n",
    "opt_ex_rl: OptimalExerciseRL = OptimalExerciseRL(\n",
    "    spot_price=spot_price_val,\n",
    "    payoff=opt_payoff,\n",
    "    expiry=expiry_val,\n",
    "    rate=rate_val,\n",
    "    vol=vol_val,\n",
    "    num_steps=num_steps_val_rl\n",
    ")\n",
    "\n",
    "# generate training data\n",
    "training_data: Sequence[TrainingDataType] = opt_ex_rl.training_sim_data(\n",
    "    num_paths=num_training_paths_val_rl,\n",
    "    spot_price_frac=spot_price_frac_val\n",
    ")\n",
    "\n",
    "# fit the model on the training data\n",
    "flspi: LinearFunctionApprox[Tuple[float, float]] = fitted_lspi_put_option(\n",
    "    obj=opt_ex_rl,\n",
    "    strike=strike_val,\n",
    "    expiry=expiry_val,\n",
    "    training_data=training_data,\n",
    "    training_iters=num_training_iters_val_rl,\n",
    "    split=split_val_rl\n",
    ")\n",
    "\n",
    "# get the optimal vf for each step\n",
    "vf_seq_rl = []\n",
    "prices: np.ndarray = np.arange(120.0)\n",
    "for step in range(num_steps_val_rl + 1):\n",
    "    exer_curve_rl: np.ndarray = opt_ex_rl.exercise_curve(\n",
    "        step=step,\n",
    "        prices=prices\n",
    "    )\n",
    "    cont_curve_rl: np.ndarray = opt_ex_rl.continuation_curve(\n",
    "        func=flspi,\n",
    "        step=step,\n",
    "        prices=prices\n",
    "    )\n",
    "    vf_seq_rl.append([(prices, np.maximum(cont_curve_rl, exer_curve_rl))])\n",
    "\n",
    "# get the exercise boundary\n",
    "ex_boundary_rl: Sequence[float] = opt_ex_rl.put_option_exercise_boundary(\n",
    "    func=flspi,\n",
    "    strike=strike_val\n",
    ")\n",
    "\n",
    "# generate testing data\n",
    "scoring_data: np.ndarray = opt_ex_rl.scoring_sim_data(\n",
    "    num_paths=num_scoring_paths_val_rl\n",
    ")\n",
    "\n",
    "# get the price \n",
    "price_rl: float = opt_ex_rl.option_price(\n",
    "    scoring_data=scoring_data,\n",
    "    func=flspi\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dad6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "063cb0c4",
   "metadata": {},
   "source": [
    "### Compare the exercise boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35dd1527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Scholes European Option Price = 7.459\n",
      "\n",
      "Best Model American Option Price = 7.973\n",
      "\n",
      "Binary Tree American Option Price = 7.969\n",
      "\n",
      "ADP American Option Price = 11.32168\n",
      "\n",
      "Longstaff-Schwartz American Option Price = 7.72434\n",
      "\n",
      "RL American Option Price = 7.853\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAI/CAYAAADkwzGCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABZEElEQVR4nO3deZicVZ33/8+p6qU6ve/dSWeFJGQPoZFFIEAgoAFBR7ZRw6AOOio0zKiIjkwudEZnnAcMz+CCgsTx+QUwyhLjEtlFIpCEkH2j01l739P7cn5/VHeTTnqvrq5T1e+XF1dX33fVXd/quk3Xp8+5v8dYawUAAAAAcJMn1AUAAAAAAPpHaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIdFhboAScrIyLDTpk0LdRkAAAAAEBJbtmypsNZm9rXPidA2bdo0bd68OdRlAAAAAEBIGGMO97eP6ZEAAAAA4DBCGwAAAAA4jNAGAAAAAA5z4pq2vrS1tenYsWNqbm4OdSk4jc/nU15enqKjo0NdCgAAABDxnA1tx44dU2JioqZNmyZjTKjLQRdrrSorK3Xs2DFNnz491OUAAAAAEc/Z6ZHNzc1KT08nsDnGGKP09HRGQAEAAIAx4mxok0RgcxTvCwAAADB2nA5toeb1erV48WItWrRIS5Ys0Ztvvjmi4/zwhz9UY2Njn/suv/xyTZkyRdbanm033nijEhIShvUc//AP/6B169YFfB8AAAAAbiG0DSAuLk7btm3Te++9p+9973u6//77R3ScgUKbJKWkpOivf/2rJKmmpkbFxcUjeh4AAAAAkYfQNkR1dXVKTU3t+f4HP/iBzj//fC1cuFD/9m//JklqaGjQihUrtGjRIs2fP19PP/20HnnkEZ04cUJXXHGFrrjiij6Pfeutt+qpp56SJP32t7/VJz7xiZ591lp97Wtf0/z587VgwQI9/fTTPdu/8pWvaO7cuVqxYoXKysp6HrNlyxYtXbpU5513nq655hpCIAAAABDGnO0e6YKmpiYtXrxYzc3NKi4u1ssvvyxJ2rhxow4cOKC3335b1lp97GMf0+uvv67y8nJNnDhRGzZskCTV1tYqOTlZDz30kF555RVlZGT0+TzLli3TP/7jP6qjo0NPPfWUHnvsMX3nO9+R5A9x3aN9FRUVOv/883XZZZdp06ZN2rdvn3bs2KHS0lLNnTtXn/3sZ9XW1qa77rpLzz//vDIzM/X000/rW9/6lp544omx+aEBAAAAGFVhEdr+eM8fVbKtZFSPmbM4R9f+8NoB79M9PVKSNm3apJUrV2rnzp3auHGjNm7cqHPPPVeSdPLkSR04cECXXnqpvvrVr+q+++7Tddddp0svvXRItXi9Xl1yySV6+umn1dTUpGnTpvXse+ONN3TbbbfJ6/UqOztbS5cu1TvvvKPXX3+9Z/vEiRN15ZVXSpL27dunnTt36uqrr5YkdXR0KDc3d5g/HQAAAACuCIvQ5oKLLrpIFRUVKi8vl7VW999/v77whS+ccb8tW7bo97//ve6//34tX75cDzzwwJCOf+utt+rjH/+4Vq1a1Wv7qQ1KTtdXF0drrebNm6dNmzYN6XkBAAAAuC0sQttgI2JjYe/evero6FB6erquueYaffvb39anPvUpJSQk6Pjx44qOjlZ7e7vS0tL06U9/WgkJCXryySclSYmJiaqvr+93eqQkXXrppbr//vt122239dp+2WWX6ac//aluv/12VVVV6fXXX9cPfvADtbe366c//alWrlypsrIyvfLKK/r7v/97zZ49W+Xl5dq0aZMuuugitbW1af/+/Zo3b14wfzwAAAAAgiQsQluodF/TJvlHsNasWSOv16vly5drz549uuiiiyRJCQkJ+tWvfqWDBw/qa1/7mjwej6Kjo/XjH/9YknTnnXfqIx/5iHJzc/XKK6/0+VzGGH31q189Y/vHP/5xbdq0SYsWLZIxRv/1X/+lnJwcffzjH9fLL7+sBQsWaNasWVq6dKkkKSYmRuvWrdPdd9+t2tpatbe365577iG0AQAAAGHKDDT9bqzk5+fbzZs399q2Z88ezZkzJ0QVYTC8PwAAAMDoMcZssdbm97WPlv8AAAAA4DBCGwAAAAA4jNAGAAAAAA4bNLQZY54wxpQZY3aesi3NGPNnY8yBrq+pp+y73xhz0BizzxhzTbAKBwAAAIDxYCgjbU9KOr3n/jckvWStnSnppa7vZYyZK+lWSfO6HvMjY4x31KoFAAAAgH5sKNyg5euWa+GahVq+brk2FG7o2Vf76Ld0IH+O9pxzjg7kz1Hto98KYaXDM2jLf2vt68aYaadtvkHS5V2310h6VdJ9Xdufsta2SDpkjDko6UOSWOkZAAAAQNBsKNygVW+uUnNHsySpuKFYq95cJUm65A9vqvhHv5HtMJKM2k9KxT/6jSQp+cv/HqKKh26k17RlW2uLJanra1bX9kmSjp5yv2Nd28KS1+vV4sWLtWjRIi1ZskRvvvmmJOnEiRP65Cc/GdTn3rx5s+6+++4B7/Pqq6/quuuu67XtT3/6kxYvXqzFixcrISFBs2fP1uLFi7Vy5cpglgsAAACE1Oqtq3sCW7fmjmat3rpaZb/4bVdg+4DtMCr7xW/HssQRG+3FtU0f2/pcCM4Yc6ekOyVpypQpo1zG6IiLi9O2bdsk+cPQ/fffr9dee00TJ07UunXrgvrc+fn5ys/vc5mGAV1zzTW65hr/pYSXX365/vu///uM43R0dMjrZdYqAAAAIkdJQ0m/29tPWvUVVfzb3TfSkbZSY0yuJHV9LevafkzS5FPulyfpRF8HsNY+Zq3Nt9bmZ2ZmjrCMsVNXV6fUVH+/laKiIs2fP1+S9OSTT+oTn/iErr32Ws2cOVNf//rXex6zdu1aLViwQPPnz9d9993Xsz0hIUH33XefzjvvPF111VV6++23dfnll2vGjBl64YUXJPUeRXv77bd18cUX69xzz9XFF1+sffv2Dbv+adOm6cEHH9Qll1yiX//619q4caMuuugiLVmyRDfddJNOnjwpSdqyZYuWLl2q8847T9dcc42Ki4tH9gMDAAAAxlBOfE6/26MS+hpbUr/bXTPS0PaCpNu7bt8u6flTtt9qjIk1xkyXNFPS24GVGDpNTU1avHixzjnnHH3+85/Xt7/97T7vt23bNj399NPasWOHnn76aR09elQnTpzQfffdp5dfflnbtm3TO++8o+eee06S1NDQoMsvv1xbtmxRYmKi/vVf/1V//vOf9eyzz+qBBx444/jnnHOOXn/9db377rt68MEH9c1vfnNEr8fn8+mNN97QVVddpe9+97t68cUXtXXrVuXn5+uhhx5SW1ub7rrrLq1bt05btmzRZz/7WX3rW+FzgSYAAADGr4IlBfJ5fb22+bw+FSwpUNYdn5DxWrV1fjDR0Hitsu74xFiXOSKDTo80xqyVv+lIhjHmmKR/k/R9Sc8YYz4n6YikmyTJWrvLGPOMpN2S2iV92VrbEaTag+7U6ZGbNm3SypUrtXPnzjPut2zZMiUnJ0uS5s6dq8OHD6uyslKXX365ukcRP/WpT+n111/XjTfeqJiYGF17rb8h54IFCxQbG6vo6GgtWLBARUVFZxy/trZWt99+uw4cOCBjjNra2kb0em655RZJ0t/+9jft3r1bH/7whyVJra2tuuiii7Rv3z7t3LlTV199tST/NMrc3NwRPRcAAAAwllbMWCHJf21bSUOJcuJzVLCkwL/9yytUftzome95tWzKn5WVWa2sO/4uLJqQSEPrHnlbP7uW9XP/f5cUkle/5XC1Vr+4XwVXzdJ5U1MHf8AwXHTRRaqoqFB5efkZ+2JjY3tue71etbe3y9r+58dGR0fLGP9QrMfj6Xm8x+NRe3v7Gff/9re/rSuuuELPPvusioqKdPnll4/oNcTHx0uSrLW6+uqrtXbt2l77d+zYoXnz5mnTJpp9AgAAIPysmLGiJ7ydrjL3eln9UfrKDzTzax8e48oCM9LpkU5a/eJ+vX6gQqtf3D/qx967d686OjqUnp4+pPtfcMEFeu2111RRUaGOjg6tXbtWS5cuHdFz19bWatIkfxPOJ598ckTHONWFF16ov/71rzp48KAkqbGxUfv379fs2bNVXl7eE9ra2tq0a9eugJ8PAAAACLXizf5eDSVb+25Y4rLR7h4ZUgVXzer1NVDd17RJ/tGpNWvWDLnrYm5urr73ve/piiuukLVWH/3oR3XDDTeMqI6vf/3ruv322/XQQw/pyiuvHNExTpWZmaknn3xSt912m1paWiRJ3/3udzVr1iytW7dOd999t2pra9Xe3q577rlH8+bNC/g5AQAAgFA6seVEr6/hxAw0jW+s5Ofn282bN/fatmfPHs2ZMydEFWEwvD8AAABwXfflU1++eLr+NP8nikmIUUtdi75R+w3FJsUOfoAxZIzZYq3tc82viBppAwAAAIBu3ZdP+Q5Ua1Kn1bLvLVPeRXmKnhAd6tKGhdAGAAAAICJ1XzZ19ZFG7ZZ0zo3nKHFiYmiLGoGIakQCAAAAAN3Om5qqX37uAkUdqlFCbkJYBjaJ0AYAAAAgwhVvKdbE8yaGuowRI7QBAAAAiFitJ1tVvqdcufm5oS5lxAhtAAAAACJWybYSyYqRtkj27LPPyhijvXv3SpKKiooUFxenc889V3PmzNGHPvQhrVmzpuf+Tz75pDIzM7V48WLNnTtXP/vZz0JVOgAAADDundjsX5ct9zxG2iLW2rVrdckll+ipp57q2XbWWWfp3Xff1Z49e/TUU0/p4Ycf1i9+8Yue/bfccou2bdumV199Vd/85jdVWloaitIBAACAca94S7ESJyYqMTc8m5BIhLYBnTx5Un/961/1+OOP9wptp5oxY4YeeughPfLII2fsy8rK0llnnaXDhw8Hu1QAAAAA8i+ovfLxt7TlcLUk/0jbxPyJfe4LF5ET2rY/Iz08X1qV4v+6/ZmAD/ncc8/p2muv1axZs5SWlqatW7f2eb8lS5b0TJ88VWFhoQoLC3X22WcHXAsAAACAwXUvqL36xf1qqW9Rxb6KnqmRp+4LJ5GxuPb2Z6T1d0ttTf7va4/6v5ekhTeP+LBr167VPffcI0m69dZbtXbtWn35y18+437W2l7fP/3003rjjTcUGxurn/70p0pLSxtxDQAAAACGrntB7YKrZqnk3a4mJF0jbafuCyeREdpeevCDwNatrcm/fYShrbKyUi+//LJ27twpY4w6OjpkjNGXvvSlM+777rvvas6cOT3f33LLLfqf//mfET0vAAAAgJHrXlBbkjb91j8brnuk7dR94SQypkfWHhve9iFYt26dVq5cqcOHD6uoqEhHjx7V9OnTdexY72MWFRXpq1/9qu66664RPxcAAACA0Ve8uVhJeUlKyE4IdSkBiYyRtuQ8/5TIvraP0Nq1a/WNb3yj17a/+7u/03/8x3/o/fff17nnnqvm5mYlJibqrrvu0h133DHi5wIAAAAwejo7OtXZ1qkTW06Edav/bub067FCIT8/327evLnXtj179vSacjig069pk6ToOOn6RwK6pg39G9b7AwAAAIyh177zmrb+bKvqjtbp8gcv19JvLw11SYMyxmyx1ub3tS8ypkcuvNkf0JInSzL+rwQ2AAAAYFwq/HOh6o7WSfqgCUk4i4zpkZI/oBHSAAAAgHFly+FqrX5xvwqumqXzpqaqs6NTxVuLe/ZPPI/QBgAAAAAh0732miT955Ipqj9er7aGNklS0uQkxWfFh7K8UUFoAwAAABC2Tl177alLn9TJkpOSpIw5GZp88eRQljZqCG0AAAAAwlb32mv1J+r1u67r2GISYvRPO/5JxmNCXN3oiIxGJAAAAACGbEPhBi1ft1wL1yzU8nXLtaFwQ6hLCtjxd4733M49L1cer0fGREZoY6RtAAkJCTp58mSvbfv27dMXvvAF1dTUqKWlRZdeeqkee+yxEFUIAAAADM+Gwg1a9eYqNXc0S5KKG4q16s1VkqQVM1aMyfOv3rpaJQ0lyonPUcGSghE/797n9qp8d7mqD1Wr7WRbz/aJ54d/85FTEdqG6e6779a9996rG264QZK0Y8eOEFcEAAAADN3qrat7Alu35o5mrd66OuihbbDAONxA9+Z/v6mjfz3a833W/CxN/NBELfrMoqC+jrFGaBum4uJi5eXl9Xy/YMGCEFYDAAAADE9JQ8mwtg/XQMFroMAoaVgjgJ3tvVv7S1LeRXm6/rHrR+V1uCRirmkbq3m59957r6688kp95CMf0cMPP6yampqgPA8AAAAQDDnxOcPaPhzdI2nFDcWysj3Bq/uz+UCBcbBAJ0nWWm0uqtLKn/9Nr/35oNqb2nvdP9KmRXaLiNA22Mkxmu644w7t2bNHN910k1599VVdeOGFamlpGfXnAQAAAIKhYEmBfF5fr20+r08FSwoCPvZgwWugwDiUEcAd/98OvbDwp8r4+qt68bMvSJK8MV5F+fwTCPMuyOvzGOEuIkLbUFL5aJo4caI++9nP6vnnn1dUVJR27twZlOcBAAAARtuKGSu06uJVyo3PlZFRbnyuVl28qtcUxJHOYhsseA0UGIcyAnjw9wflrW9VcnWLYkoa5Evx6Y6/3KEvbv+ibvvdbcpemD2kOsNNRFzTFux5uaf64x//qGXLlik6OlolJSWqrKzUpEmTRv15AAAAgGBZMWNFvw0+AukumROfo+KG4j63n/r4/q55O/V5pTNHAI+/fVynmvShSZr0If9n8fSZ6QPWFs4iIrQNdnKMVGNjY6+mI//8z/+sY8eOqaCgQD6f/y8EP/jBD5STE/j8XwAAAESe0WxvP1aG0l2yv9dVsKRg0ODVX2DsK9DdvehuTX17qkrqS9RU2aSqg1W9HhOp17CdLiJC21BOjpHo7Ozsc/tDDz0U0HEBAAAQ+UK9HtpIDTaLbSiva6RB9fRAt/e5vXr6tqflifZI1r8tZ3GOoidEq2Jvhc7+yNkjeYlhJyJCW6AnBwAAADDaAhmxCqXBZrEN9roGmno5XMf+dkyS1NnWNZhipNtfvV2+ZN8Aj4o8ERHapIHn5QIAAABjbTRGrEJhsFlsY9lP4vRr2DLOyRh3gU2KoNAGAAAAjFQwRrwCHbEKlcFmsQWrn8TOp3bq4B8PqqmySennpKv+eL1ObD7R6z7dTUfGG0IbAAAAxrVgjXi5NGI1XAPNYgtGP4kth6v1zIOvasKeSv+G332w76wvnKe3K0/q0jlZuvATc0f8HOEsItZpAwAAgPtGuvZXsA225u9gdfe3f7D10IayLpmLhrLO23Ct3rhPUe/X9Lnvlbw4vXBWotZPjVfOYrd/NsHCSBsAAACCztXrt6SBR7wGq3uw/WM9YjVWRtpPoqO1Q1XvVyk6LlqxybGqP1Gv2MRYrUxP0l9bO864f2xyrP7pU+eq7eUDKrhq1miUHpYIbQPwer1asGCB2tvbNX36dP3v//6vUlJSVFRUpOuuu047d+4MdYkAAABhwdXrt6SBr9EarO5AXtd47IC++SebtfFfNiomMUbeaK8aKxrlS/Wps93fHTIhJ0HRE6JVfahaKVNTlL0wW/nT0/TLz10Q4spDi9A2gLi4OG3btk2SdPvtt+vRRx/Vt771rdAWBQAAEIZcvn5roBGv+/9yf5+P6a470Nc13jqgH379sDrbO9Vc/cHPuqmySZIUmxSrL+36kryxXjXXNCsmIUbGY3o93sUlEsYC17QN0UUXXaTjx48PfkcAAACcweXrtwa6Rmuwul1+XS7qXnetLxPPn6i4tDjFxMcoaVKSfMk+xSbG9uzvnopa3FAsK9szFdWVayODKWJG2mrXr1fZwz9Ue3GxonJzlXXvPUq+/vpROXZHR4deeuklfe5znxuV4wEAAIw3o3H9VjBHWfob8Rqs7nC+Li1YGsoatPFfNiprYZYkqWx7mbIXZ6upskn1x+v7fdxg7fxdnmIbbBER2mrXr1fxtx+Qbfa/ie0nTqj42w9IUkDBrampSYsXL1ZRUZHOO+88XX311aNSLwAAwHgT6PVboWpkMljdwb4uzeXpgFsOV2v1i/tVcNUsnTc1tWf7nmf3aPuvtve+868+uHnhvReq2iO9s+mILlx2ljI9HtUerdXCzywc8LguT7ENtogIbWUP/7AnsHWzzc0qe/iHAYW27mvaamtrdd111+nRRx/V3XffHWi5AAAA41Ig12+FcpRlsLqDdV2ayx03JWn1i/v1+oEKSerVKOT43/q/pMgb49Wy7y3TZ3+1Ra9Htat8avwZTUb6O26wFvUOBxFxTVt78Zlv3kDbhys5OVmPPPKI/vu//1ttbW2jckwAAAAM3XgcZRls/bhQ+8fZOVo6OUVfXJyn2iO1am1o1cmSkwNet5azOEdRsVEquGqWLpuZ0Wcb//72FSwpkM/r67VtvExFjYiRtqjcXLWfONHn9tFy7rnnatGiRXrqqad06aWXat++fcrLy+vZ//DDD+umm24atecDAADABwYbZRlsGqHL0wz743JQrSmq0SuXr9G5k5L0ZssmvVzdrIScBLU2tKqpsklxaXHqaOuQrL8rZFN1k6JiozR16VRJ0nlTU/tt49/fvvG4REK3iAhtWffe0+uaNkkyPp+y7r0noOOePHmy1/fr16/vuc2IGwAAwOgaKFgN1PAj0AWwXeXydMDDfzks22FVe6S2Z9upt29cc6OyFvgbkcSlxqmxslGeKI8mpE8I6HnH2xIJ3SJiemTy9dcr9zsPKmriRMkYRU2cqNzvPDhq3SMBAAAQXIO1cx+oLf9g0whdn2bYH5enAw40BVJGmnrZVKVMTVHK1BTFJsUqdXqqkicnK3pC9NgVGUEiYqRN8gc3QhoAAEB4Gkqjkf5GWQabRujyNMOBhGI6oLVWf7j7D0o7O03VhdXyRnuVNDlJFXsrFJcap/iseJXtLNPxt/tvNpI1L0uxSbH97sfwRUxoAwAAQPgKJFgNNo3Q5WmGgxnr6YBVB6r0zv+8M6T7zrtlnqJ8UUo9K1UxCTEqebdEGXMylJSXFOQqxx+np0daa0NdAvrA+wIAAEZbfwFqKMFqsGmELk8zHGtbDldr5eNvacvh6j73PfD914Z8rAWfWqAbn7xRS7+9VDGfOEfPLp2oCX8/X4s+s2hYz4vBORvafD6fKisrCQiOsdaqsrJSPp9v8DsDwDi3oXCDlq9broVrFmr5uuU91+YAOFMgwWqg692Gsn+8qD5Urf/73E5tf/OoHn36PTVWNqp0R6nqjtWpsaJRP/7FFlW9O/Qpo3kXftBJvXtttdUv7u/zvoPtx8CMC6EoPz/fbt68ude2trY2HTt2TM2nLZqN0PP5fMrLy1N0NBeSAkB/Tu9WJ/k/gI7HD4rAUIVjW/5wYTut/k/u/1FbR6daqpoUk+xTdLRHjeWNmpAxQTJSY3mjOuKiNCEhRi3ljUqdkSprrWqKapQ6I1XNze1qPFGv+CnJSkiK1T9t/6ee4285XK3VL+5XwVWzdN7U1DOef7D9kIwxW6y1+X3uczW0AQAQzpavW97nNTS58bna+MmNfDgFMKbKd5frR/N+NKT7XvbAZcr/Qr5iEmMkK7WebFVscqw62zvV1tAmX4pP7S3tikuNC3LV48tAoY1GJAAABMFATRXCdc2ocEZIxnh3dNPRId8378I8JU5M7Pn+1E6QvmT/FFZa948tQhsAAEEwULe6obQ2x+ghJCNSVeyr0IYvblDGnAx5Y7wqebdEWQv9C1qXbS9T9uJsdbZ1qnx3uYwxQz5u3gV5g98JY4rQBgBAEBQsKejzmraCJQW6/y/39/kY19eMCleEZESq3et2q+jVIhW9WtSz7fDrh/u8LUkzrp6hSRdMUs6iHDXXNKvuWJ2y5mepobxBTVVNyjgnQ/XH6xWXxrRH1xDaAAAIgoEWxV29dXXYrhkVjsJ1YWVgMMfePDas+0+9bKou+9fLglQNgonQBgBAkPS3KO5Ao3AYfeG8sDIiw5A6K/5prz7ZbHT+pVMl65/6mDUvS+0t7dr61jE9X1mvWxdM1MROKeOcDDVVNenY34YX2vIu6j3tkY6P4YPQBgDAGBtoFA6jj5CMUOteo0ySfvm5C/rcf/gP7+vd597Xe9H+ZZQ72zrlOeX2RI/RG0YyHVaeaI9sp5XtsGqZkqSGpjYldlrNXjJRtUdqZTutUqalqOpglUpb21UR7VF2besZ16oNpa6B9mPsENoAABihQDoS9jcKh9FHSA4ftevXq+zhH6q9uFhRubnKuvceJV9/fajLCljBVbN6fe1r/6+e3ivJH9C6nXrb22n73L78iY/piaIKrRxktOzGq2YpJiFm2HUNtB9jh3XaAAAYARbPBkZX7fr1Kv72A7LNH/x/yvh8yv3Og2EV3Ho+W1tJ3Q0bB7ttpSc+/MSwpzv6Un36esXXZTxD7wwJd7FOGwAAo4yOhJGDNdzcUPbwD3sFNkmyzc0qe/iHYRXanr/jeZXtKFP57nLlLM5RW1Obqg5WKXthtlrqWlR31N+xsbGiUY2VjcqYnaH64nrVHauTN8arzvZOGY+RJ8qj9uZ2eWO8Mh7jvx3rlTH+21G+KE2+eDKBbZwgtAEAwt5AH7qD9YGcjoSRYShruAVyDhEIh669+MxmMQNtd5G1VvvX71dTVZMk9Ro5O7bpg9tH3zza5+2PPf4xpZ6VKuMxSsxNVM3hGkVPiFZ8Zryq3q9SXFqc4lLjVLm/Ugk5CfKl+sbgVcEFhDYAQFgb6EO3pKAtqkxHwsgw2IhpIAtzs6j38ETl5qr9xIk+t4eLyn2VPYFtJGZdN0vxWfE936ednTbobYwPhDYAQFgb6EN39+2+9gX6oZmOhG4Z6YjWYCOmgUyDHa9TaEf6XmTde0+f17Rl3XvPiGsZSUv7HWt3qO5onfZtPqGtUVaX5KVoQnWzchblqKmqSfXF9cqan6WD+yr0zq5SfXjpdCU3tPk7Oda1jLjWtLPTegLbQHXTpn98IrQBAMLaSKYpjsYURjoSuiOQEa3BRkwDmQY7HqfQBvJedF+3NprdI0fS0v4v//4Xle8qlyRlSto3wPFTJO16+Uivbb5Unxb/w2L97li1qvZWKnNSom5edrZKt5cqeUqyYpNj9exvdulglDQlJ1FLo2OUOS9TCbkJQ6qbNv3jE6ENABDWBvvQHcwpjOOxbb+LLdkDGdEabMQ0kGmw43EKbaCji8nXXz+q59NwW9o3VTf1BLaRmnzxZF3z0DXK6Brx+kwfI16+m+dq9Yv7dXs/o2ED1U2b/vGJlv8AgDERrIYMA7Xel0Rb/lEUypbsA50/C9cslNWZn2eMjLbfvj2gYw+2tEMgj41Egb4XgbDW6sCGA0qfna62xjbVH69X+ux0tdS2qKG8QWlnp6mpskkt9S1KmZaihtIGdbR1KCkvSfXH62W8RtXvV+u5258LqI4r//1KXfrNS0fnRWFcoeU/ACCkgtmQYSjTFJnCODpC1ZJ9sPMn0BGtgUZMBzq/BqtrPE6hDeXo4uHXD2vt9WsV5fN/vO1ui3/qbWutOlo6FOWLUmdHp2yHlTfGq462DhljZDxGxmuUMi1F8VnxKt9drsTcRPlSfCrdUarU6amKjo9W6fZSpc9KV1RslEreK1HW/CwZY1S6o1Rnf+TsoL9WjD+MtAEAgm75uuV9fpDLjc/Vxk9uHPTxwWybTkv2odszZ67U1+cGYzRnz+6gPe9g50+oRrQCPa8jUShHF1/7zmt69YFXAz5O7nm5+vxbn5fxGNlOK2OMZNT3bflH+E697fF6Aq4B4xMjbQCAkAqkIUMwR+loyT48oWrJPtj5E6oRrfHYaEQa+A8dI3kv2lva5YnySFbq7OiUJ8oj22llO6280V7/iFj37fZOWfvBbUnyRHnU0daho3892u9zDMfkD0/uCV7G+8HC1f3eVt+3gdFEaAMABF0gU6aC2TZ9vLZkH6lgtGQfiqGcP6FoCuNyo5Gxuoa0rz90DOe9KN9drp8s/omyF2Sro7VDlQcqlTU/S22Nbao9XKuMORlqqWtRQ2mD0mZ2XZNW16LUGamqP1Ev22mVlJekmqIatbf4p0B2T4U0HqO2xjZFT4iWpCHfnnrp1IB/TsBoI7RFEKb4AHBVIGuaBXM0g5GS4f2+CEZL9qFwdU08V+sK5gjyUP/QMdR1xlr/dFCdbZ0q3vpB+C3eMvjtUxewPllysuf2gu9eoT/WNejWy2ZoyfxsVRdWa0L6BMUmxarqYJWO2E79cstR3TwpVfkfypMnyqOqg1VKOytNttPq7b8d1fer61RwuJr10eAUQluEYIoPAJcFMn0tmKMZLo+UBEugvy9GuyX7ULja0MPVuoYSrIK1GHlPDUNcZ+y6N0ZnSmO333k79LLpVHNJja5cMVspU1N69qVMS9Gqx9/S6zWNas+coGtnZ0iS0s5K67nP2r8c1OvvV0ov7md9NDiF0BYhmOIDwHUjnb4WzNEMV0dKgilcf1+4uiaei3UNFqxGEtxrimq0/s71ujDmQjW0Nyj5WLJqJtfI0+lR0vEktZ3Vpt9v/r2qDlQpe1G2rjxer5wdJVpYZ/XCphfUWNGojDkZOnnipC6paFCa7dC8XbU68vaZ10iOVEJugr506yK1v3RgxGuYsT4aXEX3yAgRynVRQokpocD4QPfI0TNef1+MJ4N1tRxJ18tND23Sxn8JTkfMC++9ULHJsfIl+xSfHa/yXeVKyE1QXGqcSreXKmV6imITY1X8brEyzsnwt9nf1tVm32NU8l6JchbnyBPl0YLbFgSlRmAs0D1yHGCKD1NCgUgWzNEMF0dKgmk8/r4YbwYbQR7JtZxH/nJkdIs8xbmfO1dZ87L63Lfg7xf0eXvhpxf23F6kRUGrDXAFoS1CMMXHLxym+ABAKI3H3xfjxc6ndio2KVbJ25N1d8Ld+t3x36lzf6e8M7y6ftb1SlybqL3z92rurrnqeL9DtVNq5WnzKLEkUTVTapShDL3xn28oe2G2mqqadLL4pDLnZepkyUkdeSM4oc2X6lPmnMygHBuIJIS2COHqxdDBNF67vgGDqV2/fsy7+wVqvE1RDKVg/77gvQyNjrYOvfC5F9TW2Nazba7m9tw+2PU/SZqjOf0e5yW91O++s689W8Zj1NneqeRpyaoprFFUXJQSchNUua9SE9InaELmBJXtKFPS5CTFJseqdFup0mamKXpCtEreLVHmvEx5ojwq2Vai7EXZis+Kl/GwthkwGEJbBGGKzwfbgfGqdv36XutotZ84oeJvPyBJzgY3pjqPvWD9vuC99AukNfxIH1u8tbhXYAuGZy8p1f2fvmPQuq7rZ/+vR/k1D3U/EAk8oS4AGKmCJQXyeX29tjHFB+Nd2cM/7LXwsSTZ5maVPfzD0BQ0BANNdcbIbCjcoOXrlmvhmoVavm65NhRuGJPn5b306279vvrF/Wquadbxt4/r+DvHVXu0Vkc3HdWPn9isLVtO6Kc/fkul20tVe7RWRa8VqWxXmR59+j0deLFQP/rVVtUU1ajwpUJVHaxSdWG1Cl8s1KNrt2nbW8f02P/dpJrDNarYW6FDrxxS0StFQX1NLYkt2pP5rFa/uH/Q1zzc/YE8dij7gUjASBvC1nicEorxY6RTzNqLzxx9Hmi7C5jqPLpCOdrFe+l3auv317/7ut5a/ZZkJG+MV+1N7Zoa7dEkSZ6WDj3+f7dKRmpraFN0fLRmWGlqY5u8Ew7pR997q2e75L/PjAnRmtzRKU9Lh370k20926N8UYrPjldzfasaM+KUaqWOuhalzkhVY0Wj2hrbFJ2ToKqjtYr3RSt1UqJqD9cqJiFGcelxqjpYpahUn6oleUuq1JjWqI7YDiUdT9LJrJOqnl4tT0yNCq5wr5U+rfYxHtDyHwAcc/qHbsk/irzq4lWDfug+cOUytZ84c92jqIkTNfPl/q9VCaWRtB9H/0L58+S9PNNj+Y+peMvY/NFk8R2L9dFHPypvjFed7Z2yndZ/u61T1n5wW5I80R51tHbIeIw8Ub1vf/Spj+pE8wnJSKbDyHqsZKScpJxx+z4CY2Gglv9MjwQAxwQyxSzr3ntkfL2nDRufT1n33jOaJY4qpjqPrlCOdrn+XjZWNKq9uV0t9S3+2y3taqnz3+5o7VBzbbOaqpr8t2ua1VTtv91U1aTmmmZ1tHaosbJRzbVdtysa1VLXovaWdv/t+ha1N/tvtza0qqGsQSXvjt0o45RLpyg6Lloer0dRsVEf3Pb1vh3li5LH61F0XLSiYs+8fddFdyk2NlbWa9UZ0ykbZRUbE+vM+wiMR0yP7EM4dl4DEDkC+dDd/W9VOP0bxlTn0RXKJk0uv5fle8r14wU/VtpZaepo7VDd8TqlTk9VW1ObGssblTwlWS31LWqtb1XixEQ1VTeps61T8dnxOllyUlGxUfKl+FR3vE6+ZJ9iEmJUe6RW8VnxivJFqbqwWkl5SfLGeFV1sEop01PU3twu22kVkxgjT5RHzdXN8qX6Q23PbSs11/hv2w6rlvoW+VJ86mzrVHtzu2ISY/zH6bCKjo9W68lWeaO98sZ61VLXougJ0f5j1zRr2tJpo/Kzcvl9BMYrpkee5vTOa5L/r9S533nQ6Q89ACLHYFPMaKmOgQQyvTaSvfXIW/pjwR/H/HmN1+hLu76kmPgY1RfXKykvSZ1tnWooa1DS5CS1NbapqapJyZOT1VLXopb6FiXlJflH/Fo6lJCboMaKRtlOq/iseDWUNsgT5VFcepzqT9QrOi5avlSf6o7VKffc3DF/fQBGD9MjhyEcO68h/NSuX68DVy7TnjlzdeDKZapdvz7UJcEhA00x6/5AXtxQLCvb02RirLoDwn0rZqzQqotXKTc+V0ZGufG5ox7Ythyu1srH39KWw9XD3h+qxx75S3AWhx5M7rm5Ouzz6it/2qOSrAlKzE1U8pRkTcyfqITsBKVOT1VxRpz+af1OHYo2yj03V/GZ8cqYnaHshdna29iqf3mzUEcTohWfGa+s+VnKOCdD8ZnxylmUo6JYj/7phZ06keY747kD+XkNZT+AscP0yNOEY+c1hJdwXEcLY2ugqUnL1y3v93q3UI+iMALojmCv29ndYl2Sfvm5C4a8f+2v1mrbPduVlFGvnz9i9KeyXE2aM0lRviiVbCtR1vws7TxRq9yiOj0zbbN25yapbFeZchbnqL25XQe3FSsm1adf/+db+ktLp7IXZquxolENZQ3KnJup7TtKlF7fqqfztujtTiPjMUqekqzKA5VqqmySNZKxkjWSxxjZTtuzsLPttOo0kjFG5rTtxmPUaa3/sR4jzynbB3vslMumjPjnFcjPOtDHDmU/gLETUGgzxtwr6fOSrKQdku6QNEHS05KmSSqSdLO1Nmz+RBOVm9t357VcphxgdAw0mktoQ7f+PnS72lKdRZXHl5G0YN9QuEEbn9yoaZXTNKHSPyrUpjYVlRT13Odk8UlN6P5mV4UKd/kDw8Hig5L8H1omV7dIkmol1R6p7XlsdWG1fJJ8klTVrLKu7aXbS3vuM+e+i/VadYM+dul0LZqbpbJdZUqenKyYxBi9/WqRfl9Wq1s+PF1plU3KOCdDxmNUvrtcmXMzted4nZ5bv0ef+MQ8nZ0Sp+rCamXNz1JLXYu2v1ei9VX1+uTMLOXFRCl9ZrpOlpxUW1ObplwyRRnNbcP+eQXysx6Nxw5lP4CxM+Jr2owxkyS9IWmutbbJGPOMpN9Lmiupylr7fWPMNySlWmvvG+hYXNOG8WTPnLlSX/+/M0Zz9uwe+4IQVlxtqe5qXXDH8nXLNf+e+Uo+nhyyGr6898vKmJ0RsucHgIEMdE1boNMjoyTFGWPa5B9hOyHpfkmXd+1fI+lVSQOGNpeEY+c1hBdGcxGIgiUFfTaZCHUrbldHAOH37hPv6shfjqjueJ2y5mepoaxBzdXNSp+drrpjdepo7VDqjFRVF1YrKjZKiZMSVbG3QnFpcZqQOUHlu8qVNClJsSmxKn2vVKlnpSomPkYl20qUMSdD3mivf3rjgiwZY1S2o0zZi7LV0dqhir0Vylmco7zNeSENbPFZ8UqflR6y5weAQATUPdIYUyDp3yU1Sdporf2UMabGWptyyn2qrbWpAx3HpZE2INgYzUWgXLx2jJE2t/3s/J/pxOYz/1gUCjtu2qHW+Fb5anyqm1SnrJYs/eP0f1T6rHTVHa9TZ1unUqalqPpQV4CcmKiKff4AGZ8Vr7IdZUrKS5IvxaeS90qUdlaaoidEq+S9EmXOyZQnyqPS7aXKWpAlWalspz9AStL8W+aH+NUDQP8GGmkLZHpkqqTfSLpFUo2kX0taJ+l/hhLajDF3SrpTkqZMmXLe4cOHR1QHEI5YCxCRhjbz7mqpa9F/pv6nbGfol/jpiO7Q8z96Xp3RnZI4RwDgVMGaHnmVpEPW2vKuJ/mtpIsllRpjcq21xcaYXKnnWuBerLWPSXpM8o+0BVAHEHaSr7+ekIaIEm6L8W45XK3VL+5XwVWzdN7UMyeDDLS/v32lO0r19v+8rfpYrzaV1etc69FZ87IUkxij0vdKlT4rXcWNrXr75UKdf9k0Tc6IV+l7pcpamCXbaVW+q1ztU5P0l12lWuSJ0twPT1ZrfatqDtcoe0G2Gisbdfj9am217bogJV5pXo/SZqap9rC/GUddQrQ2vXFYS2Zn6uzZGSrfU674rHg11zQ7EdgkKWVJirJTsnudIznei7Xy8bdG9b0I9mOHsh8ARlMgoe2IpAuNMRPknx65TNJmSQ2Sbpf0/a6vzwdaJADAfcFuMz+agtFGfctjW7T1sa2SpAxJRyUd1ZnNhRIl7d10Qnv7qS1d0jFJx36zp8/9GZLe7/rvdMmS3n/lyBn7PFEeVV4zTQcaWzWnqVPXf3SWonxRKt1Wqsx5mTJeo+ee3a19Po+mp03Q5XE+ZS/OVntTu6oOVOnllhYdPV6ns2Q0d6lHm/ZuUntluzRNujDmQu0/GKN9xmqWx6tr5uf0tNmPTYzVC4crVbW3Upl5Sbr1ix/SP1//z71qW/n4W7TDBzAmXLy8YKhGHNqstW8ZY9ZJ2iqpXdK78o+cJUh6xhjzOfmD3U2jUSgAAKMlGG3UD7/m7jT/iedP1EcfvU6rX9yv2/oZGYq7dZ5Wv7hft/exf0rXqNK0BYf1k/0/UPPsD6bB7vLu0sp//JoqdkzVp/t4bFrXYz9z1SzN7uN5Q9XSnnb4wPgS7kvTBNSIZLTQiAT9Cee/iAAYXbt/s1ttjW09nQk72zpVvqdcOYtz1NbQpqr3q5SzKEfNNc29uiQ2VfnX3Dq9S6I3xqukvCRV7quUL9Xnb3Kxs0xJk05rchEf7e+SeE6GvDFe/5TGBVmS1FNLc02z/vCVP4T4J9S/D3/jw7rqe1cFfBwazgAIV+Hw71cwW/4DQRPufxEBMLo2/vPGXospu2jhpxcqOj5a1YXV/jBX3az6E/W92uynzUpT/fF6dbR2KGV6imoO1fQEyO42+90BMnFionypvj7b7HuiPCrbXqasBVmy1qp8Z3mvNvvZi7LV1tim6verteDvF4zK62NpBwDhKtz//SK0wVmrt67u1YlOkpo7mrV662pCGzDO1BTVOB/YonxRuv7n1ysqNnJ/tebE5/T5l+qc+JwQVAMAQxfu/35F7m8WhL1w/4sI4KLO9k5temiTshdmq6W+RbWHa5W1IEtNVU1qKG1Q5txMnSw5qZb6FqXPTFftkVpZa5UyNUVVB6sUHR+txNxEf2fCzHhNyJig0h2lSp6crNhk/8LLaWenKSouSqXvlSpzrr/JRen2UmUvzJbtsCrf7R8Ram9uV+X+SuUsyvHXcqRWWfO7ailrUOacTNUX16utoU0NZQ2h/tENKu+ivIgObJK7i7sDwGDC/d+vyP7tgrAW7n8RwfgQqpbiI33soZcP6cX7Xhzpyw2p6FSfanPiNXthtjzFDYpJiFFCboLKd/tb2zfGenXg7eOaNidDObmJKt3mb7Mf5YtS4dvHdDwxWnMmJavt/WrlLMpRZ0enynf5r4krq2zUofdKdPYFeUq0Us3hGn+YrWxS2dFaHZ4QpbOjoxTXYXu12U+emqzDO0p1tKlNKdfN7LPucGxZ39++cFvaAQC6hfu/X4Q2OCvc/yKC8SFULcVH+thDrxwa2gtzUPX0ZP366sm6bGZGn6955eNv6fXpE/rc391W3r/vlr4fOzdpCI/t53kPVKgk2asb+qg7HFvWD7QvnJZ2AIBThfO/X4Q2OCvc/yKCyFO6vVS1R2pVf6JemfMy1VjeqI9Xtcknr65vMdr+q+1KmZ6i2sO1Ml6jz6QkKLHsuD4y3aMjfz2i8t3lSshJUFxqnMp2luk2X4x81qNrTjTp/T+/L2+MV2U7ypQ5N1My0seON8nX6dEnfD69/ejbyl6YrbaGNlUfqtZnMhM0obFMy8tadeSNI2qsaFRTdZPSZ6Wr/ni9/q6+Uz55teJkp3Y+vVNJeUmqOlClw6+625Z+MBd87ByV5sVFVGv4cK0LADC2aPkPAEP0v8v/V4V/LvR/YyR1//N56u2+DLR/sMcG4TiTL56s5tpmJU5MVFxqnEq3lypleopiEvydCTPnZMoT7fG3tp+fJRmNuM1+/fF6tTe3K/WsPtrsp/gUn/1Bl8S41LgB2+x/euOnlTr9zGl+AABEAlr+A0CAOlo7dPSvRz/YcGpAGiwsDbR/OH83G6XjLF21VGddfdYwnhgAAIQSoQ3AqLGdVlsf36rsBdlqPdmq2iO1ypyXqaaqJjWWNyrjnAydLD2p1vpWpZ2dprpjders6FTK1BRVH6pWVGyUEicmqnK/f7HjCRkTVLGnQokTExWbHKuyHWVKnZGqqLgole0oU/rsdP9aVTvLlDXPv1ZVxZ4KZc3PUntLu6oOVg1ey8lWpc5IVf3xetlOq6TJSaopqlGUL0qJuR/U0lDWoLbGtlD/iAPmifJo8sWTQ10GAAAYBkIbgFFz6OVD+t2dv/NP1ZP8oz8D3T59euFQHxeM20OpRdLUpVPlS/Evdpw2M03Rcf5pfJlzM+WJ8qh0e6l/seNOq/JdXYsdt3Socn+lshdlq7W+VTVFNcpemK2mqiadLDmpzHldbfbrWpQ+q6vNfqdVyrSuNvsT/G32K/ZWaELGhA/a7E9JVmxS7LBqiUmIUUx8TN9vIAAAcBKhDRgl4da6OxiP7elM2N/UwcFuj/Rxwbjdx7bsRdlasOYG/2tefU2fP68/BPF93DCUxz5yZl2nH3u06wrHcxcAgHBCaANGSV8tstub2/XeL99TxpwM/XTDHpVuK9FPD1Trmx85R5X7KpW1IEvtTe16Ys0W7ens0GO7KvTFBROVOTdTTZVNaqrydwP82S+36OjRWv2ksEb3njtZMlLy5GRVvV+lmIQY/eRvRTr+Xol+tqNc2bctVvmuciVPSVZMQoye+PHftL+tTT85WK0vTs9UxpwMGWNUvrtcmfMy9dPnd6lke6l+8n61vnnVbFUXVitrQZZaalv0xNpt2t3Rrp9tL1P0+VP9nQlP1Ku9pV2p01P1819s1uGSev2ksEZ3z5+ooleKQvgOBN+0y6c52YI9lMcO17oAAAgnhDZglPTVInvH2h363Rf80wUnSZpkJW08rDX/9VavaXdZVlph/N++0MfUvFxJuVbS+kL92v7Nv++UaXx5kvKsJFOkxx/Zcsaxr+069u/6OPapdf3y+2fWdV3XY5+1W894bI6VciTp+ff12+7jXTBJzdXNSshJULPPq2PvFit3VobSMyb4uwHOzpA31qujW4tVkebT9Mx4tRys/qAz4W5/Z8LKqkYV761Q3pJcxbV2qu6YvzNhY0WjqorrVZIUrbxOo1grpc5IVU1RjTxRHiVNTtKxnWWq6OzUtLPT1XaoRgm5Cb26JDZ6jI5tPaGJ87KUmuzr1SXx2LYSVaT7NC11glqLapSzKEdtTW2qOlileTfPU8GkhDPe54HOgdHa7+qxw7UuAADCCS3/gSB69jPPavuvtoe6jDH1mT9/RjOumhHqMgAAAMIKLf8x5mqP1KrotSL/mkyTkvwd+FJ8mpA5QeW7y5U4MVG+FJ/KdpQpZXqKoidE93QD9EZ7/Q0U5vu7AZbvLlf2gmx1tHY1c1jo7wZYc7hGWfOz1Fzd7G/mMDdTJ0u7mjnMTPd3JmzvVMo0f2fCXrV0dSYcrJbTOxMOt5aea7zGCU80nQkBAABGG6ENQfHG99/Q5h8zeipJUy+bqs72Tn+AnJ6i6verFRUXdUY3wLKdZUrKS5IvxffBAsMTolXy3mmLHS/IkqxUtrOspzNhxb4K5SzO8QfIQ6d1JpybqYayBjXXNp8ZZgu7apmYqIo9XbVkTlDZjjIlTU6SL7mrlrOH1pkwNjFW0ROiQ/0jBwAAiCiENgTFoZfH1wjTQK7/+fVKn5ke6jIAAAAQpghtDmhtaNWrq15V6vRUWWsVkxCjhJwEVeypUHxWvOLS4lS2s6xnTaaS90qUPjNdUb4o/yjM3Ex5vB6V7ihV9oJsdXZ0NXNYlKP25nZVHvBP42upa1Hd0a5mDpWN/gWG52ToZPFJtTa0qjIxRr978aCWzc3WwnNzVXWwqlctZR5pw6EKLYvzad7iXMUkxqh0e6nSZ6brUF2z/rh+j665dpbyYqNVua8y1D9WJ7Sn+nQo2qivyOZKm37qCqyu/mwo3KDVW1erpKFEOfE5KlhSoBUzVgz58QAAAN0IbQ6IjovWtl9sU1NlU6hLUZakHdqlHf3snyhpT9d/p0uXtPm3B9Q9KXL2DbMVkxCj8t3l2h/nVUVVoyY1duiCq2aopdYfIDPn+1vbb9tZqqPxUZpkjeamTVDa2WmqKaqR8Rhta2pVY1GNEtPidMn5eSrfVa6EnAT50vzXoe3v7NCJ1nZNrW3TeRdP8YfZbSXKnJcp4zF659VDOpoco+z4GM1sscpZ3NUN8ECV9k3wqKqsUTltnbroyhlqLG9UY4U/zNafqNeO9yt1NNarvHar+XnJSp6SrMr9lYpNitWW2iY1F1ZrQna8Ljl3osq2lyllWopiEmNUsq1EB6KlA7EeHX7pgFOtzl1twR6udfVlQ+EGrXpzlZo7miVJxQ3FWvXmKkkiuAEAgGEjtDnAeIymXzFdu9ftDnUpoyYuLU63/PYWGY+/R3z3aMXf9TNaMbNr/y197J/bte/zg4yE9HfsKV37bxtglOWTgxz75j72z+7a99khjND0hRbsbhw70Lr6snrr6p7A1q25o1mrt64mtAEDYIQaAPpGy39HvPPjd/T7L/0+1GWMmjl/N0c3r7s51GUAIbFwzUJZnflvq5HR9tvH1xIQwFCdPkItST6vT6suXkVwAzAu0PI/DMz5+Bzt+c0efzfA1g5V7q1U9qJstTac0g2wukknT5xU5ryuboA1zUqfna76Y/XqaO3wdyYsrFaUz98NsHJfpeLS4vzdAE/pTFj6XqlSz0pV9IRolb5XqvRzerfZl07pTNhdy+Ls3p0J+6plVrrqj9ero61DSz6/JMQ/USB0cuJzVNxQ3Od2AH1jhBoA+kdoc0RCToJWvrgy1GUAGAUFSwr6HDEoWFIQwqoAt5U0lAxrOwCMJ55QFwB3bTlcrZWPv6Uth6uHvT9Ujw3lsYFuK2as0KqLVyk3PldGRrnxuUzxAgbR30g0I9QAwEgbBhCu3fxCdWzgVCtmrCCkAcPACDUA9I/Qhn6Faze/UB0bACJBqDo4dj8H3SMB4Ex0jwQAAJLo4AgAoTRQ90iuaQMAAJIG7uAIAAgdQhsAAJBEB0c4YPsz0sPzpVUp/q/bnwl1RYATCG0AAEASHRwRYtufkdbfLdUelWT9X9ffTXADRGgDAABdCpYUyOf19dpGB0eMmZcelNqaem9ra/JvB8Y5ukcCESRUXd8ARAY6OCKkao8NbzswjhDagAhxete34oZirXpzlSTxgQvAkLHGIEImOa9ramQf24FxjumRQISg6xsAIKwte0CKjuu9LTrOvx0Y5whtQISg6xsAIKwtvFm6/hEpebIk4/96/SP+7cA4x/RIIELkxOeouKG4z+0AAISFhTcT0oA+MNIGRAi6vgEAAEQmRtqACEHXN2D00ZEVAOACQhsQQSK16xsfnBEKdGQFALiC6ZEAnNb9wbm4oVhWtueD84bCDaEuDRGOjqwAAFcQ2gA4bbAPzhsKN2j5uuVauGahlq9bTpjDqKEjKwDAFYQ2AKMiWOFpoA/OjMIhmPrrvEpHVgDAWCO0AQhYMMPTQB+cmb6GYKIjKwDAFYQ2AAELZnga6IMz09cQTCtmrNCqi1cpNz5XRka58bladfEqmpAAAMYc3SMBBCyY4WmgpQxWb13NguIIqkjtyAogMtBdefwgtAEIWE58TlDDU38fnAuWFPRqyS4xfQ0Iuu3PSC89KNUek5LzpGUPSAtvDnVVwLjDsiTjC9MjAQQsVNf+MH0NGGPbn5HW3y3VHpVk/V/X3+3fDmBMcV33+MJIG4CADTSFUQru9I1Apq8xrQQYppcelNqaem9ra/JvZ7QNGFNc1z2+ENoAjIr+wpOr0zeGUhehDjhN7bHhbQcQNMG+NAFuYXokgKBydfrGUBbtZg044DTJecPbDiBoWJZkfCG0AQgqV6dvDFaXq2ETCKllD0jRcb23Rcf5twMYU1zXPb4wPRJAULk6fWOwulwNm0BIdV+3RvdIwAksSzJ+MNIGIKhcnb4xWF39hcpQh00g5BbeLN27U1pV4/9KYAOAoCO0AQgqV6dvDFaXq2ETAACMP8ZaG+oalJ+fbzdv3hzqMgCgF7pHAgCAsWKM2WKtze9rH9e0AUA/uFYAAAC4gOmRAAAAAOAwQhsAAAAAOIzQBgCRZvsz0sPzpVUp/q/bnwl1RQAAIABc0wYAkWT7M9L6u6W2Jv/3tUf930u0ZgcAIEwx0gYAkeSlBz8IbN3amvzbAQBAWCK0AUAkqT02vO0AAMB5hDYAiCTJecPbDgAAnEdoA4BIsuwBKTqu97boOP92AAAQlghtABBJFt4sXf+IlDxZkvF/vf4RmpAAABDG6B4JhML2Z/yNIWqP+aetLXuAD9UYPQtv5nwCACCCENqAsUZLdgAAAAwD0yOBsUZLdgAAAAwDoQ0Ya7RkBwAAwDAQ2oCxRkt2AAAADAOhDRhrtGQHAABjYEPhBi1ft1wL1yzU8nXLtaFwQ6hLwgjRiAQYa93NRugeCQdtKNyg1VtXq6ShRDnxOSpYUqAVM1aEuiwAwDBtKNygVW+uUnNHsySpuKFYq95cJUn8ux6GjLU21DUoPz/fbt68OdRlAMC4dvoveEnyeX1adfEqfsEDQJhZvm65ihuKz9ieG5+rjZ/cGIKKMBhjzBZrbX5f+5ge2Zftz0gPz5dWpfi/bn8m1BUBQNCt3rq6V2CTpOaOZq3eujpEFQEARqqkoWRY2+E2QtvputfQqj0qyX6whhbBDUCE4xc8AESOnPicYW2H2whtp2MNLQDjFL/gASByFCwpkM/r67XN5/WpYElBiCpCIAhtp2MNLQDjFL/gASByrJixQqsuXqXc+FwZGeXG53KNchije+TpkvO6pkb2sR0AIlj3L3K6RwJAZFgxYwX/hkcIQtvplj3gv4bt1CmSrKEFYJwY7Bc8SwIAADD2CG2nYw0tAOgTa/4AABAarNMGABgS1vwBACB4WKcNABAwlgQAACA0CG0AgCFhSQAAAEKD0AYAGBKWBAAAIDRoRAIAGBKWBAAAIDQIbQCAIWPNHwAAxh7TIwEAAADAYYQ2AAAAAHAYoQ0AAAAAHBZQaDPGpBhj1hlj9hpj9hhjLjLGpBlj/myMOdD1NXW0igUAAACA8SbQkbbVkv5orT1H0iJJeyR9Q9JL1tqZkl7q+h4AAAAAMAIjDm3GmCRJl0l6XJKsta3W2hpJN0ha03W3NZJuDKxEAAAAABi/AhlpmyGpXNIvjDHvGmN+boyJl5RtrS2WpK6vWaNQJwAAAACMS4GEtihJSyT92Fp7rqQGDWMqpDHmTmPMZmPM5vLy8gDKAAAAAIDIFUhoOybpmLX2ra7v18kf4kqNMbmS1PW1rK8HW2sfs9bmW2vzMzMzAygDAAAAACLXiEObtbZE0lFjzOyuTcsk7Zb0gqTbu7bdLun5gCoEAAAAgHEsKsDH3yXp/xljYiQVSrpD/iD4jDHmc5KOSLopwOcAAAAAgHEroNBmrd0mKb+PXcsCOS4AAAAAwC/QddoAAAAAAEFEaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAActKFwg5avW66FaxZq+brl2lC4IdQlAQBCJKDFtQEAwOjbULhBq95cpeaOZklScUOxVr25SpK0YsaKEFYGAAgFRtoAAHDM6q2rewJbt+aOZq3eujpEFQEAQonQBgCAY0oaSoa1HQAQ2QhtAAA4Jic+Z1jbAQCRjdAGAIBjCpYUyOf19drm8/pUsKQgRBUBAEKJRiQAADimu9nI6q2rVdJQopz4HBUsKaAJCQCMU4Q2AAActGLGCkIaAEAS0yMBAAAAwGmENgAAAABwGKENAAAAABxGaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAAAAHAYoQ0AAAAAHEZoAwAAAACHEdoAAAAAwGGENgAAAABwGKENAAAAABxGaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAAAAHAYoQ0AAAAAHEZoAwAAAACHEdoAAAAAwGGENgAAAABwGKENAAAAABxGaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAAAAHAYoQ0AAAAAHEZoAwAAAACHEdoAAAAAwGGENgAAAABwGKENAAAAABxGaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAAAAHAYoQ0AAAAAHEZoAwAAAACHEdoAAAAAwGGENgAAAABwGKENAAAAABxGaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAAAAHAYoQ0AAAAAHEZoAwAAAACHEdoAAAAAwGGENgAAAABwGKENAAAAABxGaAMAAAAAhxHaAAAAAMBhhDYAAAAAcBihDQAAAAAcRmgDAAAAAIcR2gAAAADAYYQ2AAAAAHAYoQ0AAAAAHEZoAwAAAACHEdoAAAAAwGGENgAAAABwGKENAAAAABwWcGgzxniNMe8aY37X9X2aMebPxpgDXV9TAy8TAAAAAMan0RhpK5C055TvvyHpJWvtTEkvdX0PAAAAABiBgEKbMSZP0gpJPz9l8w2S1nTdXiPpxkCeAwAAAADGs0BH2n4o6euSOk/Zlm2tLZakrq9ZAT4HAAAAAIxbIw5txpjrJJVZa7eM8PF3GmM2G2M2l5eXj7QMAAAAAIhogYy0fVjSx4wxRZKeknSlMeZXkkqNMbmS1PW1rK8HW2sfs9bmW2vzMzMzAygDAAAAACLXiEObtfZ+a22etXaapFslvWyt/bSkFyTd3nW32yU9H3CVAAAAADBOBWOdtu9LutoYc0DS1V3fAwAAAABGIGo0DmKtfVXSq123KyUtG43jAgAAAMB4F4yRNgAAAADAKCG0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAw0Yc2owxk40xrxhj9hhjdhljCrq2pxlj/myMOdD1NXX0ygUAAACA8SWQkbZ2Sf9irZ0j6UJJXzbGzJX0DUkvWWtnSnqp63sAAAAAwAiMOLRZa4uttVu7btdL2iNpkqQbJK3putsaSTcGWCMAAAAAjFujck2bMWaapHMlvSUp21pbLPmDnaSs0XgOAAAAABiPAg5txpgESb+RdI+1tm4Yj7vTGLPZGLO5vLw80DIAAAAAICIFFNqMMdHyB7b/Z639bdfmUmNMbtf+XEllfT3WWvuYtTbfWpufmZkZSBkAAAAAELEC6R5pJD0uaY+19qFTdr0g6fau27dLen7k5QEAAADA+BYVwGM/LOkzknYYY7Z1bfumpO9LesYY8zlJRyTdFFCFAAAAADCOjTi0WWvfkGT62b1spMcFAAAAAHxgVLpHAgAAAACCg9AGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOC1poM8Zca4zZZ4w5aIz5RrCeBwAAAAAiWVBCmzHGK+lRSR+RNFfSbcaYucF4rlDYULhBy9ct18I1C7V83XJtKNww5P3BfGwgdYfqNY3G64q01xzMn1coz79A6orEY7t63iM88D5GjlD9PgAQXoy1dvQPasxFklZZa6/p+v5+SbLWfq+v++fn59vNmzePeh3BsKFwg1a9uUrNHc0923xen1ZdvEorZqwYcL+koD02kLqDWVcgP6+hvK5Ie82BHnukP49gn3+B1BWJx3b1vEd4COb5g7EVqt8HANxkjNlirc3vc1+QQtsnJV1rrf181/efkXSBtfYrfd0/nELb8nXLVdxQfMb23PhcbfzkxgH3SwraYwOpO5h1BfLzGsrrGkg4vuZAjz2QYNYViFCdA6E8tqvnPcJDMM8fjK1Q/T4A4KaBQltUsJ6zj2290qEx5k5Jd0rSlClTglTG6CtpKBlw+2D7g/XYwYSqrmD8vIYqkl7zaPy8gllXIFw7B8bi2K7VNRrPi7ETzPMHYytUvw8AhJ9gNSI5JmnyKd/nSTpx6h2stY9Za/OttfmZmZlBKmP05cTnDLh9oP3BfOxgQlVXoPsDEY6vOZg/r1Cef4HUFYnHdvW8R3jgfYwcofp9ACD8BCu0vSNppjFmujEmRtKtkl4I0nONqYIlBfJ5fb22+bw+FSwpGHR/MB8bSN2hek1D2R+IcHzNwfx5hfL8C6SuSDy2q+c9wgPvY+QI1e8DAOEnKNMjrbXtxpivSPqTJK+kJ6y1u4LxXGOt++Le1VtXq6ShRDnxOSpYUtCzfbD9wXpsoHWH6jUN5dgjFc6vORg/r2DWFYhQnwOhOHao6wrG82LsBPP8wdgK1e8DAOEnKI1IhiucGpEAAAAAwGgbqBFJ0BbXBgAAAAAEjtAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4DBCGwAAAAA4jNAGAAAAAA4jtAEAAACAwwhtAAAAAOAwQhsAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMGOtDXUNMsaUSzoc6jr6kCGpItRFIKJxjiGYOL8QTJxfCCbOLwSTq+fXVGttZl87nAhtrjLGbLbW5oe6DkQuzjEEE+cXgonzC8HE+YVgCsfzi+mRAAAAAOAwQhsAAAAAOIzQNrDHQl0AIh7nGIKJ8wvBxPmFYOL8QjCF3fnFNW0AAAAA4DBG2gAAAADAYYQ2ScaYa40x+4wxB40x3+hjvzHGPNK1f7sxZkko6kR4GsL59amu82q7MeZNY8yiUNSJ8DTY+XXK/c43xnQYYz45lvUh/A3lHDPGXG6M2WaM2WWMeW2sa0T4GsLvyGRjzHpjzHtd59cdoagT4ccY84QxpswYs7Of/WH1+X7chzZjjFfSo5I+ImmupNuMMXNPu9tHJM3s+u9OST8e0yIRtoZ4fh2StNRau1DSdxSG86wRGkM8v7rv95+S/jS2FSLcDeUcM8akSPqRpI9Za+dJumms60R4GuK/YV+WtNtau0jS5ZL+jzEmZkwLRbh6UtK1A+wPq8/34z60SfqQpIPW2kJrbaukpyTdcNp9bpD0S+v3N0kpxpjcsS4UYWnQ88ta+6a1trrr279JyhvjGhG+hvLvlyTdJek3ksrGsjhEhKGcY38v6bfW2iOSZK3lPMNQDeX8spISjTFGUoKkKkntY1smwpG19nX5z5f+hNXne0KbNEnS0VO+P9a1bbj3Afoy3HPnc5L+ENSKEEkGPb+MMZMkfVzST8awLkSOofwbNktSqjHmVWPMFmPMyjGrDuFuKOfX/0iaI+mEpB2SCqy1nWNTHiJcWH2+jwp1AQ4wfWw7vaXmUO4D9GXI544x5gr5Q9slQa0IkWQo59cPJd1nre3w/6EaGJahnGNRks6TtExSnKRNxpi/WWv3B7s4hL2hnF/XSNom6UpJZ0n6szHmL9bauiDXhsgXVp/vCW3+VD35lO/z5P9rznDvA/RlSOeOMWahpJ9L+oi1tnKMakP4G8r5lS/pqa7AliHpo8aYdmvtc2NSIcLdUH9HVlhrGyQ1GGNel7RIEqENgxnK+XWHpO9b/xpVB40xhySdI+ntsSkRESysPt8zPVJ6R9JMY8z0rgtbb5X0wmn3eUHSyq4uMxdKqrXWFo91oQhLg55fxpgpkn4r6TP8ZRrDNOj5Za2dbq2dZq2dJmmdpC8R2DAMQ/kd+bykS40xUcaYCZIukLRnjOtEeBrK+XVE/lFcGWOyJc2WVDimVSJShdXn+3E/0matbTfGfEX+rmpeSU9Ya3cZY77Ytf8nkn4v6aOSDkpqlP+vPsCghnh+PSApXdKPukZD2q21+aGqGeFjiOcXMGJDOcestXuMMX+UtF1Sp6SfW2v7bLENnGqI/4Z9R9KTxpgd8k9nu89aWxGyohE2jDFr5e84mmGMOSbp3yRFS+H5+d74R5sBAAAAAC5ieiQAAAAAOIzQBgAAAAAOI7QBAAAAgMMIbQAAAADgMEIbAAAAADiM0AYAAAAADiO0AQAAAIDDCG0AAAAA4LD/H/0Hq3R5ESAhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error on the Bin Tree Optimal Exercise Boundary is \t0.85590\n",
      "\n",
      "The error on the ADP Optimal Exercise Boundary is \t7.88041\n",
      "\n",
      "The error on the LS Optimal Exercise Boundary is \t14.97339\n",
      "\n",
      "The error on the RL Optimal Exercise Boundary is \t2.71239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Black-Scholes\n",
    "print(f\"Black-Scholes European Option Price = {price_bs:.3f}\\n\")\n",
    "\n",
    "# for plotting\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Best model\n",
    "x_ex_boundary_best, y_ex_boundary_best = zip(*ex_boundary_best)\n",
    "plt.plot(x_ex_boundary_best, y_ex_boundary_best, label=\"Best Model\", color = \"purple\")\n",
    "# print the price of the american option (VF at state 0, at time 0)\n",
    "# price_best: float = vf_seq_best[0][NonTerminal(0)]\n",
    "price_best: float = vf_seq_best[0][NonTerminal(0)]\n",
    "print(f\"Best Model American Option Price = {price_best:.3f}\\n\")\n",
    "\n",
    "# Binary Tree\n",
    "x_ex_boundary_bin_tree, y_ex_boundary_bin_tree = zip(*ex_boundary_bin_tree)\n",
    "plt.scatter(x_ex_boundary_bin_tree, y_ex_boundary_bin_tree, s = 2, label=\"Binomial Tree\")\n",
    "# print the price of the american option (VF at state 0, at time 0)\n",
    "# price_bin_tree: float = vf_seq_bin_tree[0][NonTerminal(0)]\n",
    "price_bin_tree: float = vf_seq_bin_tree[0][NonTerminal(0)]\n",
    "print(f\"Binary Tree American Option Price = {price_bin_tree:.3f}\\n\")\n",
    "\n",
    "# ADP\n",
    "all_funcs: List[FunctionApprox[NonTerminal[float]]] = []\n",
    "for t, (v_opt, p) in enumerate(it_vf_adp):\n",
    "    all_funcs.append(v_opt)\n",
    "    price_adp: float = v_opt(NonTerminal(spot_price_val))\n",
    "\n",
    "y_ex_boundary_adp: Sequence[float] = opt_ex_adp.put_option_exercise_boundary(\n",
    "    all_funcs,\n",
    "    strike_val\n",
    ")\n",
    "x_ex_boundary_adp = [t * dt_adp for t in range(0, num_steps_val_adp + 1)]\n",
    "# y_ex_boundary_adp = ex_boundary_adp\n",
    "plt.scatter(x_ex_boundary_adp, y_ex_boundary_adp, label=\"ADP\")\n",
    "print(\"ADP American Option Price = %.5f\\n\" % price_adp)\n",
    "\n",
    "# LS\n",
    "x_ex_boundary_ls = [t * dt_ls for t in range(1, num_steps_val_ls + 1)]\n",
    "y_ex_boundary_ls = ex_boundary_ls\n",
    "plt.scatter(x_ex_boundary_ls, y_ex_boundary_ls, label=\"LS\")\n",
    "print(\"Longstaff-Schwartz American Option Price = %.5f\\n\" % price_ls)\n",
    "\n",
    "# RL\n",
    "x_ex_boundary_rl = [i * dt_rl for i in range(num_steps_val_rl + 1)]\n",
    "y_ex_boundary_rl = ex_boundary_rl\n",
    "plt.scatter(x_ex_boundary_rl, y_ex_boundary_rl, label=\"RL\")\n",
    "print(f\"RL American Option Price = {price_rl:.3f}\\n\")\n",
    "\n",
    "# show the plot\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# compute the error metric for each of these boundaries\n",
    "ex_boundary_error_bin_tree = ex_boundary_error_metric(x_ex_boundary_best,\n",
    "                                                      y_ex_boundary_best,\n",
    "                                                      x_ex_boundary_bin_tree,\n",
    "                                                      y_ex_boundary_bin_tree)\n",
    "print(\"The error on the Bin Tree Optimal Exercise Boundary is \\t{:.05f}\\n\".format(ex_boundary_error_bin_tree))\n",
    "\n",
    "ex_boundary_error_adp = ex_boundary_error_metric(x_ex_boundary_best,\n",
    "                                                  y_ex_boundary_best,\n",
    "                                                  x_ex_boundary_adp,\n",
    "                                                  y_ex_boundary_adp)\n",
    "print(\"The error on the ADP Optimal Exercise Boundary is \\t{:.05f}\\n\".format(ex_boundary_error_adp))\n",
    "\n",
    "ex_boundary_error_ls = ex_boundary_error_metric(x_ex_boundary_best,\n",
    "                                                  y_ex_boundary_best,\n",
    "                                                  x_ex_boundary_ls,\n",
    "                                                  y_ex_boundary_ls)\n",
    "print(\"The error on the LS Optimal Exercise Boundary is \\t{:.05f}\\n\".format(ex_boundary_error_ls))\n",
    "\n",
    "ex_boundary_error_rl = ex_boundary_error_metric(x_ex_boundary_best,\n",
    "                                                  y_ex_boundary_best,\n",
    "                                                  x_ex_boundary_rl,\n",
    "                                                  y_ex_boundary_rl)\n",
    "print(\"The error on the RL Optimal Exercise Boundary is \\t{:.05f}\\n\".format(ex_boundary_error_rl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796cd10",
   "metadata": {},
   "source": [
    "### Compare the Optimal Value Functions at each 20% time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbfd10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best\n",
    "x_best = []\n",
    "y_best = []\n",
    "skip_best = int(skip_size_val * num_steps_val_best)\n",
    "for i in range(num_steps_val_best+1):\n",
    "    if i%skip_best == 0:\n",
    "        y_best.append([vf_seq_best[i][NonTerminal(j)] for j in range(len(vf_seq_best[i]))])\n",
    "        x_best.append([opt_ex_best.state_price(i,j) for j in range(len(vf_seq_best[i]))])\n",
    "\n",
    "\n",
    "# Binary Tree\n",
    "x_bin_tree = []\n",
    "y_bin_tree = []\n",
    "skip_bin_tree = int(skip_size_val * num_steps_val_bin_tree)\n",
    "for i in range(num_steps_val_bin_tree+1):\n",
    "    if i%skip_bin_tree == 0:\n",
    "        y_bin_tree.append([vf_seq_bin_tree[i][NonTerminal(j)] for j in range(len(vf_seq_bin_tree[i]))])\n",
    "        x_bin_tree.append([opt_ex_bin_tree.state_price(i,j) for j in range(len(vf_seq_bin_tree[i]))])\n",
    "        \n",
    "# ADP\n",
    "x_adp = []\n",
    "y_adp = []\n",
    "prices: np.ndarray = np.arange(50,250.0)\n",
    "skip_adp = int(skip_size_val * num_steps_val_adp)\n",
    "for i in range(len(it_vf_adp)):\n",
    "    if i%skip_adp == 0:\n",
    "        v_opt, p = it_vf_adp[i]\n",
    "        v_opt_curve: np.ndarray = opt_ex_adp.optimal_value_curve(\n",
    "            func=v_opt,\n",
    "            prices=prices\n",
    "        )\n",
    "        x_adp.append(prices)\n",
    "        y_adp.append(v_opt_curve)\n",
    "        \n",
    "# LS\n",
    "x_ls = []\n",
    "y_ls = []\n",
    "skip_ls = int(skip_size_val * num_steps_val_ls)\n",
    "for i in range(num_steps_val_ls+1):\n",
    "    if i%skip_ls == 0:\n",
    "        x,y = zip(*vf_seq_ls[i])\n",
    "        x_ls.append(x)\n",
    "        y_ls.append(y)\n",
    "        \n",
    "# RL\n",
    "x_rl = []\n",
    "y_rl = []\n",
    "skip_rl = int(skip_size_val * num_steps_val_rl)\n",
    "for i in range(num_steps_val_rl+1):\n",
    "    if i%skip_rl == 0:\n",
    "        x,y = zip(*vf_seq_rl[i])\n",
    "        x_rl.append(x)\n",
    "        y_rl.append(y)\n",
    "\n",
    "# plot them all together\n",
    "for i in range(int(1.0 / skip_size_val) + 1):\n",
    "    print(\"Time step: {:.02f} out of {:.02f}\".format(i * skip_size_val * expiry_val, expiry_val))\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(x_best[i],y_best[i],s=5,label=\"best\")\n",
    "    plt.scatter(x_bin_tree[i],y_bin_tree[i],s=5,label=\"bin_tree\")\n",
    "    plt.scatter(x_adp[i],y_adp[i],s=5,label=\"ADP\")\n",
    "    plt.scatter(x_ls[i],y_ls[i],s=5,label=\"LS\")\n",
    "    plt.scatter(x_rl[i],y_rl[i],s=5,label=\"RL\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlim(0,200)\n",
    "    plt.show()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac757cf5",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- create a README for these notebooks\n",
    "    - the README should say that in order to use the notebook, one must clone the code from rl book and put it in this floder\n",
    "    - the readme folder should also explicitely cite the RL book and Ashwin's code\n",
    "    - it should explain that I am the student and that Ashwin is the supervisor\n",
    "- **make the code so that I only get back the vfs at each step and the exercise boundary for each approach.**\n",
    "    - the name of the function should be the same for all (same interface)\n",
    "- remove the plots from the LS code\n",
    "- define the metric (as a function) and have the true exercise curve and the ex curve to evaluate as arguments\n",
    "- fix the Bin tree approach, I believe that it is broken because the rate is between steps and not time, which is why it drops so fast with many steps.\n",
    "- fix the fact that binary tree takes state as number while, others have states as price... or is it really an issue?\n",
    "- clean the code and add/fix docstrings and types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd873d12",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- Remove all the spurious dependance and the NonTerminal() things, I woul like this code to be self-contained\n",
    "- In ADP, have an argument that selects the approach with possibility to select from all the approach I have used (Lstsq with laguerre poly, linear interpolation, bspline, an maybe locally weighted lstsq\n",
    "- compute the execution time of each approach, maybe as a function or their parameters\n",
    "- use the metric to compute how close the execution boundary are to binomial tree\n",
    "- should discuss next steps in my analysis:\n",
    "    - develop a more general methodology for ADP because now I rely on choosing the s to better fit the bin tree solution\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd199cb",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- Longstaff shwartz gives a good price, but the ex_boundary is off. When increasing the number of traces it gets better.\n",
    "- How should I go about comparing the 3 approaches, they all have different parameters, different execution times, different ex boundary depending on the parameters chosen..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fd3d4",
   "metadata": {},
   "source": [
    "## Meeting with Prof Rao\n",
    "- provide a perspective to what makes ls work well on both conceptual and technical level\n",
    "- what can we learn about it, and how could this learning maybe create a RL algorithm that would potentially be better than LS\n",
    "- make the 3 way comparison\n",
    "    - problem in comparison\n",
    "        - bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbdc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41dab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
